{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDA Binary Classification with a Bank Dataset","metadata":{}},{"cell_type":"markdown","source":"### This EDA refers to Kaggle playground competition: \"Binary Classification with a Bank Dataset\" \n- Competition link: https://www.kaggle.com/competitions/playground-series-s5e8\n- Main goal of this competition is to predict whether a client will subscribe to a bank term deposit.\n- Submissions are evaluated using ROC AUC between the predicted value and the observed target.\n- The dataset for this competition (both train and test) was generated from a deep learning model trained on the Bank Marketing Dataset dataset. Feature distributions are close to, but not exactly the same, as the original.\n- Start Date - August 1, 2025\n- Final Submission Deadline - August 31, 2025","metadata":{}},{"cell_type":"markdown","source":"### Labels details from original data set","metadata":{}},{"cell_type":"markdown","source":"- age: Age of the client (numeric)\n- job: Type of job (categorical: \"admin.\", \"blue-collar\", \"entrepreneur\", etc.)\n- marital: Marital status (categorical: \"married\", \"single\", \"divorced\")\n- education: Level of education (categorical: \"primary\", \"secondary\", \"tertiary\", \"unknown\")\n- default: Has credit in default? (categorical: \"yes\", \"no\")\n- balance: Average yearly balance in euros (numeric)\n- housing: Has a housing loan? (categorical: \"yes\", \"no\")\n- loan: Has a personal loan? (categorical: \"yes\", \"no\")\n- contact: Type of communication contact (categorical: \"unknown\", \"telephone\", \"cellular\")\n- day: Last contact day of the month (numeric, 1-31)\n- month: Last contact month of the year (categorical: \"jan\", \"feb\", \"mar\", …, \"dec\")\n- duration: Last contact duration in seconds (numeric)\n- campaign: Number of contacts performed during this campaign (numeric)\n- pdays: Number of days since the client was last contacted from a previous campaign (numeric; -1 means the client was not previously contacted)\n- previous: Number of contacts performed before this campaign (numeric)\n- poutcome: Outcome of the previous marketing campaign (categorical: \"unknown\", \"other\", \"failure\", \"success\")\n- y: The target variable, whether the client subscribed to a term deposit","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom lightgbm import LGBMRegressor, LGBMClassifier\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.manifold import TSNE\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nwarnings.filterwarnings(\"ignore\",  category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning,)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:18.341349Z","iopub.execute_input":"2025-08-03T09:11:18.341632Z","iopub.status.idle":"2025-08-03T09:11:28.203066Z","shell.execute_reply.started":"2025-08-03T09:11:18.341569Z","shell.execute_reply":"2025-08-03T09:11:28.202280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv')\nsub_df = pd.read_csv('/kaggle/input/playground-series-s5e8/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:22:17.208450Z","iopub.execute_input":"2025-08-03T09:22:17.208774Z","iopub.status.idle":"2025-08-03T09:22:19.200165Z","shell.execute_reply.started":"2025-08-03T09:22:17.208750Z","shell.execute_reply":"2025-08-03T09:22:19.199171Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Basic check of data","metadata":{}},{"cell_type":"code","source":"display(train_df.head(4))\ndisplay(test_df.head(4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:31.348269Z","iopub.execute_input":"2025-08-03T09:11:31.348599Z","iopub.status.idle":"2025-08-03T09:11:31.389232Z","shell.execute_reply.started":"2025-08-03T09:11:31.348575Z","shell.execute_reply":"2025-08-03T09:11:31.388006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(train_df.info())\ndisplay(test_df.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:31.390392Z","iopub.execute_input":"2025-08-03T09:11:31.390739Z","iopub.status.idle":"2025-08-03T09:11:31.875239Z","shell.execute_reply.started":"2025-08-03T09:11:31.390706Z","shell.execute_reply":"2025-08-03T09:11:31.874309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(\"Summary for TRAIN data:\",train_df.describe())\ndisplay(\"Summary for TEST data:\",test_df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:31.876543Z","iopub.execute_input":"2025-08-03T09:11:31.876889Z","iopub.status.idle":"2025-08-03T09:11:32.179027Z","shell.execute_reply.started":"2025-08-03T09:11:31.876857Z","shell.execute_reply":"2025-08-03T09:11:32.178030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(\"TRAIN data\", train_df.nunique())\nprint('\\n')\ndisplay('TEST data',test_df.nunique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:32.180305Z","iopub.execute_input":"2025-08-03T09:11:32.180562Z","iopub.status.idle":"2025-08-03T09:11:32.718452Z","shell.execute_reply.started":"2025-08-03T09:11:32.180540Z","shell.execute_reply":"2025-08-03T09:11:32.717610Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- We have 7 numeric columns and 9 with categories\n- month column can be mapped to numerical column if needed\n- One coulmn with id in both train/test sets and additional column with labels in train set\n- number of unique values different for columns age, balance, duration, campaign, pdays, previous\n- min values different for train - test set for column duration\n- max values different balance, campaign, previous\n- pdays have two separate information - first number of days and second == -1 means the client was not previously contacted. Can be separated into two columns to separate category from numeric","metadata":{}},{"cell_type":"markdown","source":"### BONUS: Dimensions reduction with t-SNE","metadata":{}},{"cell_type":"code","source":"X = train_df.drop(columns=['id', 'y'])\ny = train_df['y']\n\n# Separation of numeric and categorical columns\ncat_cols = X.select_dtypes(include='object').columns.tolist()\nnum_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n\n# Pipeline: przetwarzanie cech\npreprocessor = ColumnTransformer([\n    ('num', StandardScaler(), num_cols),\n    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols)\n])\n\nX_processed = preprocessor.fit_transform(X)\n\n# Dimensions reduction with t-SNE\n# t-SNE is very slow for large datasets. We will check only 20k random samples\nSAMPLE_SIZE = 20000\n\nidx = np.random.choice(len(X_processed), SAMPLE_SIZE, replace=False)\nX_sample = X_processed[idx]\ny_sample = y.iloc[idx]\n\ntsne = TSNE(n_components=2, perplexity=30, learning_rate=200, n_iter=1000, random_state=42)\nX_tsne = tsne.fit_transform(X_sample)\n\n\n# Creating plot\nplt.figure(figsize=(10, 8))\nsns.scatterplot(\n    x=X_tsne[:, 0],\n    y=X_tsne[:, 1],\n    hue=y_sample,\n#    palette='coolwarm',\n    s=5,\n    alpha=0.6,\n    linewidth=0\n)\nplt.title(\"t-SNE 2D wizualizacja danych (kolor = y)\")\nplt.xlabel(\"t-SNE 1\")\nplt.ylabel(\"t-SNE 2\")\nplt.legend(title='y')\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:26:55.153762Z","iopub.execute_input":"2025-08-03T09:26:55.154077Z","iopub.status.idle":"2025-08-03T09:29:01.260984Z","shell.execute_reply.started":"2025-08-03T09:26:55.154052Z","shell.execute_reply":"2025-08-03T09:29:01.259999Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2nd BONUS - Separation of pdays and additional column wuth months as numeric","metadata":{}},{"cell_type":"code","source":"# we can create separate column with flag for -1 value\ntrain_df['no_previous_contact'] = (train_df['pdays'] == -1).astype(int)\ntest_df['no_previous_contact'] = (test_df['pdays'] == -1).astype(int)\n\n# We can create additional column with pdays only without -1 values\ntrain_df['pdays_cleaned'] = train_df['pdays'].where(train_df['pdays'] != -1, np.nan) \ntest_df['pdays_cleaned'] = test_df['pdays'].where(test_df['pdays'] != -1, np.nan) \n\n# We can create additional column with numeric months\ntrain_df['month_as_num'] = train_df['month'].map({'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11, 'dec':12})\ntest_df['month_as_num'] = test_df['month'].map({'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11, 'dec':12})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:32.719438Z","iopub.execute_input":"2025-08-03T09:11:32.719700Z","iopub.status.idle":"2025-08-03T09:11:32.818051Z","shell.execute_reply.started":"2025-08-03T09:11:32.719674Z","shell.execute_reply":"2025-08-03T09:11:32.817265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Duplicates and missing values check","metadata":{}},{"cell_type":"code","source":"print(\"Duplicates in TRAIN data:\", train_df.duplicated().sum())\nprint(\"Duplicates in TEST data:\", test_df.duplicated().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:32.818990Z","iopub.execute_input":"2025-08-03T09:11:32.819338Z","iopub.status.idle":"2025-08-03T09:11:33.629810Z","shell.execute_reply.started":"2025-08-03T09:11:32.819305Z","shell.execute_reply":"2025-08-03T09:11:33.629037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Missing values in TRAIN data:\\n\",train_df.isna().mean().apply(lambda x: f\"{x:.2%}\"))\nprint(\"\\nMissing values  in TEST data:\\n\",test_df.isna().mean().apply(lambda x: f\"{x:.2%}\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:33.632497Z","iopub.execute_input":"2025-08-03T09:11:33.632755Z","iopub.status.idle":"2025-08-03T09:11:34.126810Z","shell.execute_reply.started":"2025-08-03T09:11:33.632734Z","shell.execute_reply":"2025-08-03T09:11:34.125934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- There is no duplicates in train/test data\n- There are no missing data in train/test sets\n- in case we decide to clean pdays we have missing 89,66% of data \n","metadata":{"execution":{"iopub.status.busy":"2025-07-30T07:33:20.111888Z","iopub.execute_input":"2025-07-30T07:33:20.112262Z","iopub.status.idle":"2025-07-30T07:33:20.293068Z","shell.execute_reply.started":"2025-07-30T07:33:20.112230Z","shell.execute_reply":"2025-07-30T07:33:20.291808Z"}}},{"cell_type":"markdown","source":"## 3. Train-Test drift check","metadata":{}},{"cell_type":"markdown","source":"### Numeric column drift","metadata":{"execution":{"iopub.status.busy":"2025-08-01T18:45:12.402360Z","iopub.execute_input":"2025-08-01T18:45:12.402651Z","iopub.status.idle":"2025-08-01T18:45:12.407030Z","shell.execute_reply.started":"2025-08-01T18:45:12.402623Z","shell.execute_reply":"2025-08-01T18:45:12.406070Z"}}},{"cell_type":"code","source":"for col in test_df.columns:\n    if col != 'id' and test_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(train_df[col], label='test', fill=True)\n        sns.kdeplot(test_df[col], label='train', fill=True)\n        plt.title(f\"Drift check for Column: {col}\")\n        plt.legend()\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:11:34.614845Z","iopub.execute_input":"2025-08-03T09:11:34.615092Z","iopub.status.idle":"2025-08-03T09:12:17.281113Z","shell.execute_reply.started":"2025-08-03T09:11:34.615072Z","shell.execute_reply":"2025-08-03T09:12:17.280259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='balance'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.99)\n\n# Zoom \nsns.kdeplot(data=train_df, x=feature, ax=axes[0], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[0], label='test', fill=True, alpha=0.4)\naxes[0].set_xlim(-1, upper_limit)\naxes[0].set_title('Data with zoom')\n\n# Full data\nsns.kdeplot(data=train_df, x=feature, ax=axes[1], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[1], label='test', fill=True, alpha=0.4)\naxes[1].set_title('Full data')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:12:17.282114Z","iopub.execute_input":"2025-08-03T09:12:17.282393Z","iopub.status.idle":"2025-08-03T09:12:26.126934Z","shell.execute_reply.started":"2025-08-03T09:12:17.282371Z","shell.execute_reply":"2025-08-03T09:12:26.125980Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='duration'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.99)\n\n# Zoom \nsns.kdeplot(data=train_df, x=feature, ax=axes[0], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[0], label='test', fill=True, alpha=0.4)\naxes[0].set_xlim(-1, upper_limit)\naxes[0].set_title('Data with zoom')\n\n# Full data\nsns.kdeplot(data=train_df, x=feature, ax=axes[1], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[1], label='test', fill=True, alpha=0.4)\naxes[1].set_title('Full data')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:12:26.128050Z","iopub.execute_input":"2025-08-03T09:12:26.128371Z","iopub.status.idle":"2025-08-03T09:12:34.792471Z","shell.execute_reply.started":"2025-08-03T09:12:26.128348Z","shell.execute_reply":"2025-08-03T09:12:34.791313Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='campaign'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.99)\n\n# Zoom \nsns.kdeplot(data=train_df, x=feature, ax=axes[0], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[0], label='test', fill=True, alpha=0.4)\naxes[0].set_xlim(-1, upper_limit)\naxes[0].set_title('Data with zoom')\n\n# Full data\nsns.kdeplot(data=train_df, x=feature, ax=axes[1], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[1], label='test', fill=True, alpha=0.4)\naxes[1].set_title('Full data')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:12:34.793481Z","iopub.execute_input":"2025-08-03T09:12:34.793772Z","iopub.status.idle":"2025-08-03T09:12:43.340869Z","shell.execute_reply.started":"2025-08-03T09:12:34.793750Z","shell.execute_reply":"2025-08-03T09:12:43.339966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='pdays'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.9)\n\n# Zoom \nsns.kdeplot(data=train_df, x=feature, ax=axes[0], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[0], label='test', fill=True, alpha=0.4)\naxes[0].set_xlim(-1, upper_limit)\naxes[0].set_title('Data with zoom')\n\n# Full data\nsns.kdeplot(data=train_df, x=feature, ax=axes[1], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[1], label='test', fill=True, alpha=0.4)\naxes[1].set_title('Full data')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:12:43.341816Z","iopub.execute_input":"2025-08-03T09:12:43.342066Z","iopub.status.idle":"2025-08-03T09:12:52.134114Z","shell.execute_reply.started":"2025-08-03T09:12:43.342047Z","shell.execute_reply":"2025-08-03T09:12:52.133243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='previous'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.999)\n\n# Zoom \nsns.kdeplot(data=train_df, x=feature, ax=axes[0], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[0], label='test', fill=True, alpha=0.4)\naxes[0].set_xlim(-1, upper_limit)\naxes[0].set_title('Data with zoom')\n\n# Full data\nsns.kdeplot(data=train_df, x=feature, ax=axes[1], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[1], label='test', fill=True, alpha=0.4)\naxes[1].set_title('Full data')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:12:52.135245Z","iopub.execute_input":"2025-08-03T09:12:52.135558Z","iopub.status.idle":"2025-08-03T09:13:00.664717Z","shell.execute_reply.started":"2025-08-03T09:12:52.135534Z","shell.execute_reply":"2025-08-03T09:13:00.663766Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Categorical columns drift check","metadata":{}},{"cell_type":"code","source":"def plot_category_drift(feature):\n    pd.concat([\n        train_df[feature].value_counts(normalize=True).rename(\"train\"),\n        test_df[feature].value_counts(normalize=True).rename(\"test\")\n    ], axis=1).plot(kind=\"bar\", title=f\"Category drift: {feature}\")\n\ncolumns = [ 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact','month', 'poutcome'  ]\n\nfor col in columns:\n    plot_category_drift(col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:00.665653Z","iopub.execute_input":"2025-08-03T09:13:00.665878Z","iopub.status.idle":"2025-08-03T09:13:03.497162Z","shell.execute_reply.started":"2025-08-03T09:13:00.665861Z","shell.execute_reply":"2025-08-03T09:13:03.496173Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- visible drift for column 'previous'\n- no clear drift between train and test data for rest of numeric columns\n- no clear drift between train and test data for categorical columns","metadata":{}},{"cell_type":"markdown","source":"## 4. Correlation check for train and test data","metadata":{}},{"cell_type":"code","source":"sns.heatmap(train_df[['age', 'balance','day', 'duration','campaign', 'pdays','previous', 'month_as_num', 'pdays_cleaned']].corr(),\n            annot = True, cmap='coolwarm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:03.498152Z","iopub.execute_input":"2025-08-03T09:13:03.498442Z","iopub.status.idle":"2025-08-03T09:13:04.167713Z","shell.execute_reply.started":"2025-08-03T09:13:03.498421Z","shell.execute_reply":"2025-08-03T09:13:04.166710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.heatmap(test_df[['age', 'balance','day', 'duration','campaign', 'pdays','previous','month_as_num', 'pdays_cleaned']].corr(), \n            annot = True, cmap='coolwarm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:04.168687Z","iopub.execute_input":"2025-08-03T09:13:04.168989Z","iopub.status.idle":"2025-08-03T09:13:04.690926Z","shell.execute_reply.started":"2025-08-03T09:13:04.168960Z","shell.execute_reply":"2025-08-03T09:13:04.689981Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- Only pdays and previous columns show strong correlation\n- possible weak negative correlation between new columns - month_as_num and pdays_cleaned","metadata":{}},{"cell_type":"markdown","source":"## 5. Check of 'y' in each column for train data","metadata":{}},{"cell_type":"markdown","source":"### Category columns","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=train_df, x='y')\nround(train_df['y'].value_counts(normalize=True)*100,2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:04.691633Z","iopub.execute_input":"2025-08-03T09:13:04.691861Z","iopub.status.idle":"2025-08-03T09:13:04.878516Z","shell.execute_reply.started":"2025-08-03T09:13:04.691844Z","shell.execute_reply":"2025-08-03T09:13:04.877316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns = [ 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',  'poutcome', \n            'month_as_num', 'no_previous_contact']\nfor col in columns:\n    train_df.groupby([col,'y']).size().unstack().plot(kind='bar', stacked=True, title=col)\n    plt.show()\n    print('Percentage summary:')\n    display((pd.crosstab(train_df[col], train_df[\"y\"], normalize='index') * 100).round(1))\n    print('Quantitative summary:')\n    display((pd.crosstab(train_df[col], train_df[\"y\"])))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:17:17.998483Z","iopub.execute_input":"2025-08-03T09:17:17.998774Z","iopub.status.idle":"2025-08-03T09:17:22.097794Z","shell.execute_reply.started":"2025-08-03T09:17:17.998753Z","shell.execute_reply":"2025-08-03T09:17:22.097012Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- We have 2 gropus in label column with split 88% 12% - strong unbalance of classes\n- Each categorical column show caategories with different ratio of 0 / 1 labels and have potential to be used in classification\n","metadata":{}},{"cell_type":"markdown","source":"### Numerical columns","metadata":{}},{"cell_type":"code","source":"columns = [ 'age','balance', 'day', 'duration', 'campaign', 'pdays', 'previous',  'pdays_cleaned', 'month_as_num']\n\nfor feature in columns:\n    plt.figure(figsize=(8, 4))\n    sns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, label='y = 0', fill=True, alpha=0.4)\n    sns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, label='y = 1', fill=True, alpha=0.4)\n    plt.title(f'KDE for {feature}')\n    #plt.xscale('log')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:09.003885Z","iopub.execute_input":"2025-08-03T09:13:09.004132Z","iopub.status.idle":"2025-08-03T09:13:37.699984Z","shell.execute_reply.started":"2025-08-03T09:13:09.004114Z","shell.execute_reply":"2025-08-03T09:13:37.699036Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- Most of columns show differences in density for labels 0 an 1 and have good potential to be used for classification - age, day, duration, pdays_cleaned, month_as_num\n- month column seems to not show cyclical behaviour so it can be probably used as categorical column\n- day seems to have no cyclical behaviour so it can be also consider as categorical however 31 categories can be quite large number - to be checked\n- new column pdays_cleaned show differences between 0 and 1 but it consider about 11% of data, rest of them is -1\n- some plots are not so godd visible so they can be analysed in more details like previous","metadata":{}},{"cell_type":"markdown","source":"### Additional plots for more details","metadata":{}},{"cell_type":"code","source":"feature ='balance'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.99)\n\n# Zoom\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[0], label='y = 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[0], label='y = 1', fill=True, alpha=0.4)\naxes[0].set_xlim(0, upper_limit)\naxes[0].set_title(f'Zoom for {feature}')\n\n# Full\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[1], label='y = 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[1], label='y = 1', fill=True, alpha=0.4)\naxes[1].set_title(f'Full data for {feature}')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:37.700839Z","iopub.execute_input":"2025-08-03T09:13:37.701094Z","iopub.status.idle":"2025-08-03T09:13:44.633267Z","shell.execute_reply.started":"2025-08-03T09:13:37.701073Z","shell.execute_reply":"2025-08-03T09:13:44.632279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='duration'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.995)\n\n# Zoom\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[0], label='y = 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[0], label='y = 1', fill=True, alpha=0.4)\naxes[0].set_xlim(0, upper_limit)\naxes[0].set_title(f'Zoom for {feature}')\n\n# Full\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[1], label='y = 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[1], label='y = 1', fill=True, alpha=0.4)\naxes[1].set_title(f'Full data for {feature}')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:44.634310Z","iopub.execute_input":"2025-08-03T09:13:44.634803Z","iopub.status.idle":"2025-08-03T09:13:51.591802Z","shell.execute_reply.started":"2025-08-03T09:13:44.634767Z","shell.execute_reply":"2025-08-03T09:13:51.590730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='campaign'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.97)\n\n# Zoom\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[0], label='y = 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[0], label='y = 1', fill=True, alpha=0.4)\naxes[0].set_xlim(0, upper_limit)\naxes[0].set_title(f'Zoom  for {feature}')\n\n# Full\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[1], label='y = 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[1], label='y = 1', fill=True, alpha=0.4)\naxes[1].set_title(f'Full data for {feature}')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:51.592773Z","iopub.execute_input":"2025-08-03T09:13:51.593043Z","iopub.status.idle":"2025-08-03T09:13:58.463776Z","shell.execute_reply.started":"2025-08-03T09:13:51.593023Z","shell.execute_reply":"2025-08-03T09:13:58.462798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='previous'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.995)\n\n# Zoom\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[0], label='y = 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[0], label='y = 1', fill=True, alpha=0.4)\naxes[0].set_xlim(0, upper_limit)\naxes[0].set_title(f'Zoom for {feature}')\n\n# Full\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[1], label='y = 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[1], label='y = 1', fill=True, alpha=0.4)\naxes[1].set_title(f'Full data for {feature}')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:13:58.464724Z","iopub.execute_input":"2025-08-03T09:13:58.464976Z","iopub.status.idle":"2025-08-03T09:14:05.316486Z","shell.execute_reply.started":"2025-08-03T09:13:58.464955Z","shell.execute_reply":"2025-08-03T09:14:05.315163Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- Balance column show small differences in density - can be verified with feature importance\n- duration column show quite good differences in density - it is good potential for classification\n- campaign column seems to have no bigger differences -  can be verified with feature importance\n- for column previous KDE seems to show much different behaviour and seems to have a very good potential for classification","metadata":{}},{"cell_type":"markdown","source":"## 6. Outliners for numerical columns","metadata":{}},{"cell_type":"code","source":"columns = [ 'age','balance', 'day', 'duration', 'campaign', 'pdays', 'previous',  'pdays_cleaned', 'month_as_num']\n\nfor col in columns:\n    plt.figure(figsize=(6, 4))\n    sns.boxplot(x='y', y=col, data=train_df)\n    plt.title(f'Boxplot of {col} by y label column')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:14:05.322521Z","iopub.execute_input":"2025-08-03T09:14:05.322825Z","iopub.status.idle":"2025-08-03T09:14:08.082318Z","shell.execute_reply.started":"2025-08-03T09:14:05.322801Z","shell.execute_reply":"2025-08-03T09:14:08.081312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## t_SNE lub PCA ???? ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:14:08.083327Z","iopub.execute_input":"2025-08-03T09:14:08.083665Z","iopub.status.idle":"2025-08-03T09:14:08.087915Z","shell.execute_reply.started":"2025-08-03T09:14:08.083634Z","shell.execute_reply":"2025-08-03T09:14:08.087028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.countplot(data=train_df,  x='housing', hue='y')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:14:08.088862Z","iopub.execute_input":"2025-08-03T09:14:08.089247Z","iopub.status.idle":"2025-08-03T09:14:08.747084Z","shell.execute_reply.started":"2025-08-03T09:14:08.089194Z","shell.execute_reply":"2025-08-03T09:14:08.746064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.boxplot(data=train_df, x='education', y='pdays_cleaned')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:14:08.748104Z","iopub.execute_input":"2025-08-03T09:14:08.748440Z","iopub.status.idle":"2025-08-03T09:14:09.209065Z","shell.execute_reply.started":"2025-08-03T09:14:08.748411Z","shell.execute_reply":"2025-08-03T09:14:09.207864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.boxplot(data=train_df, x='marital', y='age', hue='y')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:14:09.210005Z","iopub.execute_input":"2025-08-03T09:14:09.210275Z","iopub.status.idle":"2025-08-03T09:14:10.052594Z","shell.execute_reply.started":"2025-08-03T09:14:09.210251Z","shell.execute_reply":"2025-08-03T09:14:10.051436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.pairplot(train_df[[ 'age','balance', 'pdays_cleaned','y']], hue='y') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:14:10.053599Z","iopub.execute_input":"2025-08-03T09:14:10.053858Z","iopub.status.idle":"2025-08-03T09:16:31.372930Z","shell.execute_reply.started":"2025-08-03T09:14:10.053836Z","shell.execute_reply":"2025-08-03T09:16:31.371608Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"🔧 1. Przekształcenia kolumn kategorycznych\na) One-Hot Encoding / Target Encoding\nDla zmiennych takich jak: job, marital, education, contact, month, poutcome.\n\nJeśli korzystasz z modeli drzewiastych (np. XGBoost, LightGBM), możesz użyć Target Encoding.\n\nDla regresji logistycznej czy SVM – One-Hot Encoding.\n\nb) Grupowanie kategorii\njob: Możesz pogrupować zawody wg dochodu, statusu społecznego lub stabilności zatrudnienia.\n\neducation: Połączyć unknown z primary lub stworzyć grupę \"unknown\" osobno – sprawdzić korelację z targetem.\n\nmonth: Zamienić na numer miesiąca (jan = 1 itd.) i/lub pogrupować na kwartały lub sezony (wiosna/lato/jesień/zima).\n\npoutcome: Bardzo ważna zmienna – warto zostawić jako osobną kolumnę, ale też stworzyć zmienną binarną typu: prev_success = poutcome == 'success'.\n\n🧮 2. Przekształcenia kolumn liczbowych\na) Standaryzacja / Normalizacja\nDla modeli wrażliwych na skalę (regresja logistyczna, SVM) warto przeskalować: age, balance, duration, campaign, pdays, previous.\n\nb) Transformacje logarytmiczne / winsoryzacja\nbalance, duration, pdays, previous mogą mieć rozkład z ogonami – warto sprawdzić wykresy. Spróbuj:\n\nlog(1 + balance), log(1 + duration), log(1 + previous)\n\nWinsoryzacja (obcięcie ekstremalnych wartości)\n\n🧠 3. Tworzenie nowych cech (Feature Engineering)\na) Interakcje między zmiennymi\nage * duration, job + education, contact * month, poutcome * previous – interakcje mogą ujawniać niuanse kampanii.\n\nStwórz kolumnę recently_contacted = pdays != -1 jako cecha binarna.\n\nb) Grupowanie wieku\nage_group = 'young' (<=30) / 'middle' (31–60) / 'senior' (>60) – może mieć różny wpływ na decyzje kredytowe.\n\nc) Zmienna sezonowa\nis_summer = month in ['jun', 'jul', 'aug'] – kampanie w wakacje mogą mieć inną skuteczność.\n\nd) Długość kontaktu / skuteczność kontaktu\nlong_contact = duration > X (np. 120 sekund)\n\ncampaign_efficiency = previous / (1 + campaign) – czy wiele kontaktów wcześniej przynosiło efekt?\n\n🔍 4. Sprawdzenie korelacji / ważności cech\nWykorzystaj:\n\nFeature Importance z modelu drzewiastego.\n\nPermutation Importance\n\nSHAP values – do zrozumienia wpływu cech na predykcję.\n\n🧪 5. Eksperymenty i walidacja\na) Sprawdź:\nCzy duration nie przecieka informacji? (jeśli znana tylko po kampanii – może trzeba ją pominąć).\n\nCzy pdays == -1 to tylko brak kontaktu, czy też dodatkowa informacja o “świeżym” kliencie?\n\nJaki jest rozkład targetu y – czy masz problem imbalance? Jeśli tak, rozważ:\n\nSMOTE, undersampling majority class, class_weight.\n\n✅ Przykładowe cechy do przetestowania:\nNowa kolumna\tOpis\nage_group\tkategoryczna: young / middle / senior\nlog_balance\tlog(1 + balance)\ncontacted_before\tbinary: pdays != -1\nseason\tcategorical: winter/spring/summer/fall\ncontact_efficiency\tprevious / (1 + campaign)\nlong_contact\tbinary: duration > 120\neducation_known\tbinary: education != 'unknown'","metadata":{}},{"cell_type":"markdown","source":"1. Czasowe i kampanijne zależności\n⏱️ „Długość kontaktu” / „liczba kontaktów”\nkontakt_avg_time = duration / campaign – średni czas kontaktu na jeden kontakt\n\n📉 Trend kontaktów\ndelta_contact = previous - campaign – czy liczba kontaktów wzrosła czy spadła\n\nhas_previous_contact = (pdays != 999).astype(int) – flaga, czy kontakt był wcześniej\n\n📅 Sezonowość\nZmienna month – zakoduj ją jako int (np. Jan = 1) i dodaj zmienną:\n\nis_q4_campaign = month.isin(['oct', 'nov', 'dec']) – może zimą skuteczność spada?\n\n🧑‍💼 2. Zachowanie klienta i profil demograficzny\n💳 Zobowiązania finansowe\nloan_sum = (housing == 'yes') + (loan == 'yes') – liczba aktywnych pożyczek\n\nis_deep_debt = (balance < 0) & (loan_sum > 1) – mocno zadłużony\n\n🧠 Poziom edukacji + zawód\nedu_job = education + \"_\" + job – np. \"tertiary_admin\"\n\nMożna zakodować i użyć jako cechy (one-hot lub target encoding)\n\n👫 Małżeństwo vs. wiek\nis_young_single = (age < 30) & (marital == 'single')\n\nis_old_married = (age > 60) & (marital == 'married')\n\n📞 3. Komunikacja i kanał kontaktu\n🔔 Efektywność kanału kontaktu\ncontact_success_rate = campaign / (duration + 1) – ile kontaktów na minutę\n\n🛠️ Rodzaj komunikacji + sukces poprzedni\nchannel_prev_success = contact + \"_\" + poutcome\n\n\n\n🧪 Narzędzia do wykrywania nieliniowych zależności:\npd.plotting.scatter_matrix() – szybki rzut oka\n\nsns.pairplot() – dla małej liczby kolumn\n\nsklearn.feature_selection.mutual_info_classif(X, y) – mierzy nieliniową zależność","metadata":{}},{"cell_type":"markdown","source":"1. Numeryczne ↔ Numeryczne\nPairplot (sns.pairplot)\nKilka zmiennych naraz – przegląd zależności i gęstości\nsns.pairplot(df, hue='label')  # opcjonalnie hue dla klasy binarnej\n\nScatterplot z hue / style / size\nSuper do odkrywania nieliniowych relacji\nsns.scatterplot(data=df, x='age', y='balance', hue='loan', style='marital')\n\nHeatmap korelacji (sns.heatmap)\nPokazuje mocne lub słabe powiązania liniowe\nsns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n\n2. Kategoryczne ↔ Numeryczne\nBoxplot (sns.boxplot)\nWidać mediany, rozrzut i outliery\nsns.boxplot(data=df, x='education', y='balance')\n\nViolinplot (sns.violinplot)\nTo samo co boxplot, ale z KDE – pokazuje lepiej gęstości\nsns.violinplot(data=df, x='job', y='age', hue='y', split=True)\n\nSwarmplot (sns.swarmplot)\nKażdy punkt osobno – dobry na małych zbiorach\nsns.swarmplot(data=df, x='marital', y='balance')\n\nBarplot (sns.barplot)\nŚrednia wartość cechy numerycznej dla kategorii (np. średni balance dla job)\nsns.barplot(data=df, x='job', y='balance')\n\n 3. Kategoryczne ↔ Kategoryczne\nHeatmap cross-tab (pd.crosstab + sns.heatmap)\nIle wystąpień danego połączenia\nct = pd.crosstab(df['job'], df['marital'])\nsns.heatmap(ct, annot=True, fmt='d', cmap='Blues')\n\nCountplot (sns.countplot)\nLiczba obserwacji w każdej kategorii + hue np. y\nsns.countplot(data=df, x='education', hue='y')\n\n4. Numeryczne ↔ Target binarny\nKDE Plot (sns.kdeplot)\nRozkład cechy w dwóch klasach\nsns.kdeplot(data=df[df['y'] == 0], x='age', label='No Loan')\nsns.kdeplot(data=df[df['y'] == 1], x='age', label='Loan Taken')\n\nHistogram + hue\nsns.histplot(data=df, x='balance', hue='y', bins=30, kde=True, stat='density')\n🔹 5. Dodatkowe / Interaktywne\n✅ FacetGrid\nPodzielone wykresy np. według marital i education\ng = sns.FacetGrid(df, col=\"marital\", row=\"education\", hue=\"y\")\ng.map(sns.kdeplot, \"age\", fill=True)\n\njointplot (sns.jointplot)\nScatter + marginesowe rozkłady\nsns.jointplot(data=df, x='balance', y='duration', hue='y', kind='kde')\n\n","metadata":{}},{"cell_type":"markdown","source":"## 6. Detailed check of categorical columns properties","metadata":{}},{"cell_type":"code","source":"sns.catplot(\n    data=train_df[train_df['Personality'].isin(['Introvert', 'Extrovert'])],  \n    x=\"Stage_fear\",\n    hue=\"Personality\",\n    col=\"Drained_after_socializing\",\n    kind=\"count\",\n    height=4,\n    aspect=1\n)\nplt.suptitle(\"Rozkład StageFear wg osobowości\", y=1.05)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.374186Z","iopub.execute_input":"2025-08-03T09:16:31.374520Z","iopub.status.idle":"2025-08-03T09:16:31.615904Z","shell.execute_reply.started":"2025-08-03T09:16:31.374495Z","shell.execute_reply":"2025-08-03T09:16:31.614474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.crosstab([train_df['Personality'],train_df[\"Stage_fear\"]],train_df[\"Drained_after_socializing\"]  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.616847Z","iopub.status.idle":"2025-08-03T09:16:31.617286Z","shell.execute_reply.started":"2025-08-03T09:16:31.617063Z","shell.execute_reply":"2025-08-03T09:16:31.617082Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- Stage_fear and Drained_after_socializing columns seems to be strong indicator of classification\n- In each column there is small representation of opposite group prefference (Extrovert preffers No & No, but there is small group of introverts with same prefferences)\n- It is very rare situation to have Yes - No and No - Yes answers. It is very specific minor group\n- It may be resonable to impute data Yes when other column is Yes and oposite for No, for such rare cases\n","metadata":{}},{"cell_type":"markdown","source":"####  Below we check what would be result of imputation Yes to Yes and No to No for both ways","metadata":{}},{"cell_type":"code","source":"cat_cols1 = ['Stage_fear','Drained_after_socializing']\nall_train_df=train_df[['Stage_fear','Drained_after_socializing','Personality']].copy()\nall_train_df[cat_cols1]=all_train_df[cat_cols1].fillna('Missing').astype(str)\ndisplay(pd.crosstab([all_train_df['Personality'],all_train_df[\"Stage_fear\"]],all_train_df[\"Drained_after_socializing\"]  ))\n\n\nhelp_train_df = train_df[['Stage_fear','Drained_after_socializing','Personality']].copy()\nhelp_train_df['Stage_fear'] = help_train_df['Stage_fear'].mask(help_train_df['Stage_fear'].isna() & help_train_df['Drained_after_socializing']\n                                            .notna(), help_train_df['Drained_after_socializing'])\nhelp_train_df['Drained_after_socializing'] = help_train_df['Drained_after_socializing'].mask(help_train_df['Drained_after_socializing']\n                                            .isna() & help_train_df['Stage_fear'].notna(), help_train_df['Stage_fear'])\nhelp_train_df[cat_cols1]=help_train_df[cat_cols1].fillna('Missing').astype(str)\n\ndisplay(pd.crosstab(help_train_df['Stage_fear'],help_train_df['Personality']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.618551Z","iopub.status.idle":"2025-08-03T09:16:31.618847Z","shell.execute_reply.started":"2025-08-03T09:16:31.618712Z","shell.execute_reply":"2025-08-03T09:16:31.618724Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- There is only 39 missing values for both categorical columns and for total 18524 rows it seems to be a good imputation stratego - to be tested","metadata":{}},{"cell_type":"markdown","source":"## 7. Detailed check of No-No / Yes-Yes data regarding Introverts & Extroverts groups","metadata":{}},{"cell_type":"code","source":"train_introvert_df = train_df[train_df['Personality']=='Introvert']\ntrain_extrovert_df = train_df[train_df['Personality']=='Extrovert']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"introvert_no_no_df = train_df[(train_df[\"Stage_fear\"]=='No') & (train_df[\"Drained_after_socializing\"]=='No') & (train_df['Personality']=='Introvert')]\nextrovert_yes_yes_df = train_df[(train_df[\"Stage_fear\"]=='Yes') & (train_df[\"Drained_after_socializing\"]=='Yes') & (train_df['Personality']=='Extrovert')]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in columns:\n    if train_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(introvert_no_no_df[col], label='introvert with no-no', fill=True)\n        sns.kdeplot(train_introvert_df[col], label='train_df introvert', fill=True)\n        sns.kdeplot(train_extrovert_df[col], label='train_df extrovert', fill=True)\n        plt.legend()\n        plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in columns:\n    if train_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(extrovert_yes_yes_df[col], label='extrovert with yes-yes', fill=True)\n        sns.kdeplot(train_introvert_df[col], label='train_df introvert', fill=True)\n        sns.kdeplot(train_extrovert_df[col], label='train_df extrovert', fill=True)\n        plt.legend()\n        plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in columns:\n    if train_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(extrovert_yes_yes_df[col], label='extrovert with yes-yes', fill=True)\n        sns.kdeplot(train_introvert_df[col], label='train_df introvert', fill=True)\n        sns.kdeplot(train_extrovert_df[col], label='train_df extrovert', fill=True)\n        sns.kdeplot(introvert_no_no_df[col], label='introvert with no-no', fill=True)\n        plt.legend()\n        plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- It seems like main problem of this classification. No-No answer is typical for Extroverts but some Introverts have same prefferences like No-No and has similar values for other colums (Post_frequency, Going_outsice...) like Extroverts\n- It will be extremly hard for classifiers to deal with such situation. There is some space in overlaping area between yes-yes and no-no groups and it can be marked with 0 and 1 giving clear information to model that is border condition. - Can be tested ","metadata":{}},{"cell_type":"code","source":"for col in test_df.columns:\n    if col != 'id' and test_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(introvert_no_no_df[col], label='introvert with no-no', fill=True)\n        sns.kdeplot(extrovert_yes_yes_df[col], label='extrovert with yes-yes', fill=True)\n\n        plt.legend()\n        plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Markers to be tested:\n- 'Time_spent_Alone' == 4\n- 'Social_event_attendance' == 3\n- 'Going_outside' ==3\n- 'Friends_circle_size' == 5\n- 'Post_frequency' == 3","metadata":{"execution":{"iopub.status.busy":"2025-07-30T07:33:32.890719Z","iopub.execute_input":"2025-07-30T07:33:32.891163Z","iopub.status.idle":"2025-07-30T07:33:32.897390Z","shell.execute_reply.started":"2025-07-30T07:33:32.891135Z","shell.execute_reply":"2025-07-30T07:33:32.895495Z"}}},{"cell_type":"markdown","source":"## 8. Missing values - looking for signals","metadata":{}},{"cell_type":"code","source":"excluded_cols = ['id', 'Personality']\nall_columns = train_df.columns\nfor col in all_columns:\n    if col not in excluded_cols:\n        train_df[col + '_MISS'] = train_df[col].notna().astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns = ['Time_spent_Alone_MISS','Stage_fear_MISS', 'Social_event_attendance_MISS', 'Going_outside_MISS','Drained_after_socializing_MISS', \n           'Friends_circle_size_MISS','Post_frequency_MISS']\nfor col in columns:\n    train_df.groupby([col,'Personality']).size().unstack().plot(kind='bar', stacked=True, title=col)\n    result = pd.crosstab(train_df[col],train_df['Personality'], normalize='index')*100\n    chi2, p, _, _ = chi2_contingency(result)\n    print(f\"Chi2 = {chi2:.3f}, p-value = {p:.4f} Column: {col} \")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- Columns Stage_fear_MISS and Drained_after_socializing_MISS have p-value lower then 0.05 so they can be considered as potential signal for different distribution of Introverts/Extroverts","metadata":{}},{"cell_type":"markdown","source":"## 9. Missing values - total number of non-missing data","metadata":{}},{"cell_type":"code","source":"train_df['not_MISS_total'] = train_df[columns].sum(axis=1)\ntrain_df.groupby(['not_MISS_total','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Data without NaN values')\npd.crosstab(train_df['not_MISS_total'],train_df['Personality'], normalize='index')*100","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- When number of missing values for one person increase it is observed that percentage of introverts in such grup increases too. ","metadata":{}},{"cell_type":"markdown","source":"## 10. Advanced Data Imputation ","metadata":{}},{"cell_type":"code","source":"num_cols = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size','Post_frequency']    \ncat_cols = ['Stage_fear', 'Drained_after_socializing']     \n\ncat_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n\ntrain_df[cat_cols] = cat_encoder.fit_transform(train_df[cat_cols])\nnum_imputer = IterativeImputer(estimator=LGBMRegressor(n_estimators=500, learning_rate=0.03, max_depth=6, subsample=0.8, colsample_bytree=0.8, verbosity=-1),\n                               max_iter=10, random_state=42)\n\ntrain_df[num_cols] = num_imputer.fit_transform(train_df[num_cols])\ncat_imputer = IterativeImputer(estimator=LGBMClassifier(n_estimators=500, learning_rate=0.03, max_depth=6, subsample=0.8, colsample_bytree=0.8, class_weght='balanced', verbosity=-1),\n                               max_iter=10, random_state=42)\n\ntrain_df[cat_cols] = cat_imputer.fit_transform(train_df[cat_cols])\n\ncolumns = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size','Post_frequency']\ntrain_df[columns]=train_df[columns].round().astype(int)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11. Realations check between columns","metadata":{"execution":{"iopub.status.busy":"2025-07-26T14:48:08.993241Z","iopub.execute_input":"2025-07-26T14:48:08.993576Z","iopub.status.idle":"2025-07-26T14:48:08.997773Z","shell.execute_reply.started":"2025-07-26T14:48:08.993554Z","shell.execute_reply":"2025-07-26T14:48:08.996803Z"}}},{"cell_type":"markdown","source":"### Time_spent_Alone / Going_outside","metadata":{"execution":{"iopub.status.busy":"2025-07-26T16:07:28.446182Z","iopub.execute_input":"2025-07-26T16:07:28.446498Z","iopub.status.idle":"2025-07-26T16:07:28.451114Z","shell.execute_reply.started":"2025-07-26T16:07:28.446474Z","shell.execute_reply":"2025-07-26T16:07:28.449714Z"}}},{"cell_type":"code","source":"train_df['Time_Alone_dev_Outside'] = train_df['Time_spent_Alone'] / train_df['Going_outside']\ntrain_df['Time_Alone_dev_Outside']=train_df['Time_Alone_dev_Outside'].round(2).astype(float)\ntrain_df.groupby(['Time_Alone_dev_Outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Time_Alone_dev_Outside (x):\n    try:\n        x=float(x)\n        if x <= 1:\n            return 0\n        elif x > 1 and x < 2:\n            return 1\n        elif x >= 2 and x < 100:\n            return 2\n        else:\n            return 3\n    except ValueError:\n        return 3\n\ntrain_df['Time_Alone_dev_Outside']=train_df['Time_Alone_dev_Outside'].apply(Time_Alone_dev_Outside).astype('Int64')\ntrain_df.groupby(['Time_Alone_dev_Outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\npd.crosstab(train_df[\"Time_Alone_dev_Outside\"],train_df['Personality'],normalize='index')*100 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- If columns Time_spent_Alone / Going_outside are devided we can observed quite good separation of data\n- To reduce number of features we can use clustering or write simple function, each group have different ratio\n- Can be check as additional feature to recognise groups","metadata":{"execution":{"iopub.status.busy":"2025-07-30T13:50:14.224526Z","iopub.execute_input":"2025-07-30T13:50:14.224816Z","iopub.status.idle":"2025-07-30T13:50:14.230744Z","shell.execute_reply.started":"2025-07-30T13:50:14.224796Z","shell.execute_reply":"2025-07-30T13:50:14.229624Z"}}},{"cell_type":"markdown","source":"## Social_event_attendance / Post_frequency","metadata":{}},{"cell_type":"code","source":"train_df['Social_dev_Post'] = train_df['Social_event_attendance'] / train_df['Post_frequency']\ntrain_df['Social_dev_Post']=train_df['Social_dev_Post'].round(2).astype(float)\ntrain_df.groupby(['Social_dev_Post','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Alternatywne grupowanie\ntrain_df['Social_dev_Post'] = train_df['Social_event_attendance'] / train_df['Post_frequency']\ntrain_df['Social_dev_Post']=train_df['Social_dev_Post'].round(2).astype(float)\n\ndef Social_dev_Post (x):\n    try:\n        x=float(x)\n        if x == 0:\n            return 0\n        elif x > 0 and x < 0.33:\n            return 1\n        elif x == 0.33:\n            return 2\n        elif x > 0.33 and x < 0.5:\n            return 1\n        elif x == 0.5:\n            return 4\n        elif x > 0.5 and x < 0.67:\n            return 1\n        elif x == 0.67:\n            return 4\n        elif x > 0.67 and x < 1:\n            return 1\n        elif x == 1:\n            return 4\n        elif x > 1 and x < 1.5:\n            return 1\n        elif x == 1.5:\n            return 4\n        elif x > 1.5 and x < 2:\n            return 1\n        elif x == 2:\n            return 4\n        elif x > 2 and x < 3:\n            return 1\n        elif x == 3:\n            return 2\n        elif x > 3 and x < 100:\n            return 1\n        else:\n            return 0\n    except ValueError:\n        return 0\n\ntrain_df['Social_dev_Post']=train_df['Social_dev_Post'].apply(Social_dev_Post).astype('Int64')\ntrain_df.groupby(['Social_dev_Post','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\npd.crosstab(train_df[\"Social_dev_Post\"],train_df['Personality'], normalize='index')*100","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- If columns Social_event_attendance / Post_frequency are devided we can observed quite good separation of data in fixed points\n- To reduce number of features we can use clustering or write simple function, each group have different ratio\n- Can be check as additional feature to recognise groups","metadata":{}},{"cell_type":"markdown","source":"## Going_outside * Friends_circle_size","metadata":{}},{"cell_type":"code","source":"train_df['Outside_mult_Friends'] = train_df['Going_outside'] * train_df['Friends_circle_size']\ntrain_df.groupby(['Outside_mult_Friends','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Outside_mult_Friends (x):\n    try:\n        x=float(x)\n        if x <= 11:\n            return 0\n        elif x > 11 and x <= 15:\n            return 1\n        elif x > 15 and x < 400:\n            return 2\n        else:\n            return 2\n    except ValueError:\n        return 2\n\ntrain_df['Outside_mult_Friends']=train_df['Outside_mult_Friends'].apply(Outside_mult_Friends).astype('Int64')\ntrain_df.groupby(['Outside_mult_Friends','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\npd.crosstab(train_df[\"Outside_mult_Friends\"],train_df['Personality'], normalize='index')*100","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- If columns Going_outside * Friends_circle_size are multiplied we can observed quite good separation of data \n- To reduce number of features we can use clustering or write simple function, each group have different ratio\n- Can be check as additional feature to recognise groups","metadata":{}},{"cell_type":"markdown","source":"## Going_outside - Post_frequency","metadata":{}},{"cell_type":"code","source":"train_df['Going_sub_Post']=train_df['Going_outside'] - train_df['Post_frequency']\ntrain_df.groupby(['Going_sub_Post','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Outside_mult_Friends (x):\n    try:\n        x=float(x)\n        if x <= -6:\n            return 0\n        elif x == -5 or x== -4 or x==4:\n            return 1\n        elif x == -3 or x== 3:\n            return 2\n        elif x == -2 or x== 2:\n            return 3\n        elif x == -1 or x== 0 or x==1:\n            return 4\n        elif x >= 5:\n            return 5\n        else:\n            return 6\n    except ValueError:\n        return 6\n\ntrain_df['Going_sub_Post']=train_df['Going_sub_Post'].apply(Outside_mult_Friends).astype('Int64')\ntrain_df.groupby(['Going_sub_Post','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\npd.crosstab(train_df[\"Going_sub_Post\"],train_df['Personality'], normalize='index')*100","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- If columns Going_outside - Post_frequency are subtracted from each other we can observed quite good separation of data \n- To reduce number of features we can use clustering or write simple function, each group have different ratio\n- Can be check as additional feature to recognise groups\n- group 0 is still not pure group","metadata":{}},{"cell_type":"markdown","source":"## 12. Realations check between columns - Other ","metadata":{}},{"cell_type":"markdown","source":"## Columns subtraction","metadata":{}},{"cell_type":"code","source":"train_df['subtraction']=train_df['Friends_circle_size'] - train_df['Post_frequency']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Going_outside'] - train_df['Post_frequency']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Going_outside'] - train_df['Friends_circle_size']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.650542Z","iopub.status.idle":"2025-08-03T09:16:31.650817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Social_event_attendance'] - train_df['Post_frequency']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.652019Z","iopub.status.idle":"2025-08-03T09:16:31.652373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Social_event_attendance'] - train_df['Friends_circle_size']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.653550Z","iopub.status.idle":"2025-08-03T09:16:31.653817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Social_event_attendance'] - train_df['Going_outside']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.654668Z","iopub.status.idle":"2025-08-03T09:16:31.654901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Time_spent_Alone'] - train_df['Post_frequency']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.655984Z","iopub.status.idle":"2025-08-03T09:16:31.656286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Time_spent_Alone'] - train_df['Friends_circle_size']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.657809Z","iopub.status.idle":"2025-08-03T09:16:31.658410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Time_spent_Alone'] - train_df['Going_outside']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.659177Z","iopub.status.idle":"2025-08-03T09:16:31.659501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Time_spent_Alone'] - train_df['Social_event_attendance']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.661175Z","iopub.status.idle":"2025-08-03T09:16:31.661497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Column summing","metadata":{}},{"cell_type":"code","source":"train_df['Summary']=train_df['Friends_circle_size'] + train_df['Post_frequency']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.662813Z","iopub.status.idle":"2025-08-03T09:16:31.663234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Summary']=train_df['Going_outside'] + train_df['Friends_circle_size']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.664303Z","iopub.status.idle":"2025-08-03T09:16:31.664600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Summary']=train_df['Going_outside'] + train_df['Post_frequency']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.666119Z","iopub.status.idle":"2025-08-03T09:16:31.666470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Summary']=train_df['Social_event_attendance'] + train_df['Post_frequency']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.667580Z","iopub.status.idle":"2025-08-03T09:16:31.667880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Summary']=train_df['Social_event_attendance'] + train_df['Going_outside']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.668705Z","iopub.status.idle":"2025-08-03T09:16:31.669025Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Other column multiplications and divisions","metadata":{}},{"cell_type":"code","source":"train_df['Time_alona_outside'] = train_df['Going_outside'] / train_df['Post_frequency']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Social_event_attendance'] / train_df['Post_frequency']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Time_spent_Alone'] / train_df['Post_frequency']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Time_spent_Alone'] / train_df['Friends_circle_size']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Time_spent_Alone'] / train_df['Social_event_attendance']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Time_spent_Alone'] / train_df['Going_outside']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alone_friends_circle'] = train_df['Time_spent_Alone'] / train_df['Friends_circle_size']\ntrain_df.groupby(['Time_alone_friends_circle','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\n\ntrain_df['Social_event_outside'] = train_df['Going_outside'] * train_df['Social_event_attendance']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Social_event_outside'] = train_df['Social_event_attendance'] * train_df['Friends_circle_size']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Social_event_outside'] = train_df['Social_event_attendance'] * train_df['Post_frequency']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Social_event_outside'] = train_df['Going_outside'] * train_df['Friends_circle_size']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\n\ntrain_df['Social_event_outside'] = train_df['Going_outside'] * train_df['Post_frequency']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Social_event_outside'] = train_df['Friends_circle_size'] * train_df['Post_frequency']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T09:16:31.670158Z","iopub.status.idle":"2025-08-03T09:16:31.670537Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- For checked interactions there is no pure separation between Extroverts and Introverts\n- Some additional features can be created to be tested, if there is improvement in classification\n","metadata":{}}]}