{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDA Binary Classification with a Bank Dataset","metadata":{}},{"cell_type":"markdown","source":"### This EDA refers to Kaggle playground competition: \"Binary Classification with a Bank Dataset\" \n- Competition link: https://www.kaggle.com/competitions/playground-series-s5e8\n- Main goal of this competition is to predict whether a client will subscribe to a bank term deposit.\n- Submissions are evaluated using ROC AUC between the predicted value and the observed target.\n- The dataset for this competition (both train and test) was generated from a deep learning model trained on the Bank Marketing Dataset dataset. Feature distributions are close to, but not exactly the same, as the original.\n- Start Date - August 1, 2025\n- Final Submission Deadline - August 31, 2025","metadata":{}},{"cell_type":"markdown","source":"### Labels details from oryginal data set","metadata":{}},{"cell_type":"markdown","source":"- age: Age of the client (numeric)\n- job: Type of job (categorical: \"admin.\", \"blue-collar\", \"entrepreneur\", etc.)\n- marital: Marital status (categorical: \"married\", \"single\", \"divorced\")\n- education: Level of education (categorical: \"primary\", \"secondary\", \"tertiary\", \"unknown\")\n- default: Has credit in default? (categorical: \"yes\", \"no\")\n- balance: Average yearly balance in euros (numeric)\n- housing: Has a housing loan? (categorical: \"yes\", \"no\")\n- loan: Has a personal loan? (categorical: \"yes\", \"no\")\n- contact: Type of communication contact (categorical: \"unknown\", \"telephone\", \"cellular\")\n- day: Last contact day of the month (numeric, 1-31)\n- month: Last contact month of the year (categorical: \"jan\", \"feb\", \"mar\", ‚Ä¶, \"dec\")\n- duration: Last contact duration in seconds (numeric)\n- campaign: Number of contacts performed during this campaign (numeric)\n- pdays: Number of days since the client was last contacted from a previous campaign (numeric; -1 means the client was not previously contacted)\n- previous: Number of contacts performed before this campaign (numeric)\n- poutcome: Outcome of the previous marketing campaign (categorical: \"unknown\", \"other\", \"failure\", \"success\")\n- y: The target variable, whether the client subscribed to a term deposit","metadata":{}},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\nimport numpy as np \nimport pandas as pd \nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom sklearn.preprocessing import OrdinalEncoder\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nwarnings.filterwarnings(\"ignore\",  category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning,)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:01:41.285815Z","iopub.execute_input":"2025-08-01T07:01:41.286155Z","iopub.status.idle":"2025-08-01T07:01:49.284503Z","shell.execute_reply.started":"2025-08-01T07:01:41.286127Z","shell.execute_reply":"2025-08-01T07:01:49.283489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:02:39.868461Z","iopub.execute_input":"2025-08-01T07:02:39.869565Z","iopub.status.idle":"2025-08-01T07:02:43.184851Z","shell.execute_reply.started":"2025-08-01T07:02:39.869531Z","shell.execute_reply":"2025-08-01T07:02:43.183860Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Basic check of data","metadata":{}},{"cell_type":"code","source":"display(train_df.head(4))\ndisplay(test_df.head(4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:02:58.321590Z","iopub.execute_input":"2025-08-01T07:02:58.322798Z","iopub.status.idle":"2025-08-01T07:02:58.364636Z","shell.execute_reply.started":"2025-08-01T07:02:58.322762Z","shell.execute_reply":"2025-08-01T07:02:58.363883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(train_df.info())\nprint('')\ndisplay(test_df.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:03:47.425664Z","iopub.execute_input":"2025-08-01T07:03:47.425977Z","iopub.status.idle":"2025-08-01T07:03:47.917648Z","shell.execute_reply.started":"2025-08-01T07:03:47.425955Z","shell.execute_reply":"2025-08-01T07:03:47.916732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(\"Summary for TRAIN data:\",train_df.describe())\ndisplay(\"Summary for TEST data:\",test_df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:04:24.719121Z","iopub.execute_input":"2025-08-01T07:04:24.719480Z","iopub.status.idle":"2025-08-01T07:04:25.077792Z","shell.execute_reply.started":"2025-08-01T07:04:24.719454Z","shell.execute_reply":"2025-08-01T07:04:25.076903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(\"TRAIN data\", train_df.nunique())\nprint('\\n')\ndisplay('TEST data',test_df.nunique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:04:58.473450Z","iopub.execute_input":"2025-08-01T07:04:58.473762Z","iopub.status.idle":"2025-08-01T07:04:59.006635Z","shell.execute_reply.started":"2025-08-01T07:04:58.473737Z","shell.execute_reply":"2025-08-01T07:04:59.005688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- We have 5 numeric columns and 2 with categories, One coulmn with id in both train/test sets and additional column with labels in train\n- train/test sets have same min max values and similar statistics\n- train/test sets have have same number of unique values","metadata":{}},{"cell_type":"markdown","source":"## 2. Duplicates and missing values check","metadata":{}},{"cell_type":"code","source":"display(\"Duplicates in TRAIN data:\", train_df.duplicated().sum())\ndisplay(\"Duplicates in TEST data:\", test_df.duplicated().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:05:50.435240Z","iopub.execute_input":"2025-08-01T07:05:50.435588Z","iopub.status.idle":"2025-08-01T07:05:51.148973Z","shell.execute_reply.started":"2025-08-01T07:05:50.435562Z","shell.execute_reply":"2025-08-01T07:05:51.148152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Missing values in TRAIN data:\\n\",train_df.isna().mean().apply(lambda x: f\"{x:.2%}\"))\nprint(\"\\nMissing values  in TEST data:\\n\",test_df.isna().mean().apply(lambda x: f\"{x:.2%}\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:05:57.130281Z","iopub.execute_input":"2025-08-01T07:05:57.130644Z","iopub.status.idle":"2025-08-01T07:05:57.599913Z","shell.execute_reply.started":"2025-08-01T07:05:57.130618Z","shell.execute_reply":"2025-08-01T07:05:57.599078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- There is no duplicates in train/test data\n- There are missing data in train/test sets in range 5.6% to 10.2% depending on coulumn\n- Stage_fear column has the largest amount of missing data, rest of columns have comparable number of missing values\n- There is no major difference in the amount of missing data between train/test data","metadata":{"execution":{"iopub.status.busy":"2025-07-30T07:33:20.111888Z","iopub.execute_input":"2025-07-30T07:33:20.112262Z","iopub.status.idle":"2025-07-30T07:33:20.293068Z","shell.execute_reply.started":"2025-07-30T07:33:20.112230Z","shell.execute_reply":"2025-07-30T07:33:20.291808Z"}}},{"cell_type":"markdown","source":"## 3. Train-Test drift check","metadata":{}},{"cell_type":"code","source":"from scipy.stats import ks_2samp\nfrom scipy.stats import wasserstein_distance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:53:37.069933Z","iopub.execute_input":"2025-08-01T07:53:37.070207Z","iopub.status.idle":"2025-08-01T07:53:37.086140Z","shell.execute_reply.started":"2025-08-01T07:53:37.070184Z","shell.execute_reply":"2025-08-01T07:53:37.085387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in test_df.columns:\n    if col != 'id' and test_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(train_df[col], label='test', fill=True)\n        sns.kdeplot(test_df[col], label='train', fill=True)\n        plt.legend()\n        plt.show()\n        ks_stat, p_value = ks_2samp(train_df[col], test_df[col])\n        print(f\"KS (Kolmogorov‚ÄìSmirnov) p-value for {col}: {p_value:.4f}\")\n        dist = wasserstein_distance(train_df[col], test_df[col])\n        print(f\"Wasserstein Distance: {dist}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:47:00.228361Z","iopub.execute_input":"2025-08-01T08:47:00.228667Z","iopub.status.idle":"2025-08-01T08:47:34.082488Z","shell.execute_reply.started":"2025-08-01T08:47:00.228647Z","shell.execute_reply":"2025-08-01T08:47:34.081474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='previous'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.999)\n\n# Przyciƒôty\nsns.kdeplot(data=train_df, x=feature, ax=axes[0], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[0], label='test', fill=True, alpha=0.4)\naxes[0].set_xlim(-1, upper_limit)\naxes[0].set_title('Data with zoom')\n\n# Pe≈Çen\nsns.kdeplot(data=train_df, x=feature, ax=axes[1], label='train', fill=True, alpha=0.4)\nsns.kdeplot(data=test_df, x=feature, ax=axes[1], label='test', fill=True, alpha=0.4)\naxes[1].set_title('Full data')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:46:06.896160Z","iopub.execute_input":"2025-08-01T08:46:06.896530Z","iopub.status.idle":"2025-08-01T08:46:15.471374Z","shell.execute_reply.started":"2025-08-01T08:46:06.896505Z","shell.execute_reply":"2025-08-01T08:46:15.470449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_category_drift(feature):\n    pd.concat([\n        train_df[feature].value_counts(normalize=True).rename(\"train\"),\n        test_df[feature].value_counts(normalize=True).rename(\"test\")\n    ], axis=1).plot(kind=\"bar\", title=f\"Category drift: {feature}\")\n\ncolumns = [ 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact','month', 'poutcome'  ]\n\nfor col in columns:\n    plot_category_drift(col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:42:43.941280Z","iopub.execute_input":"2025-08-01T07:42:43.941929Z","iopub.status.idle":"2025-08-01T07:42:46.552957Z","shell.execute_reply.started":"2025-08-01T07:42:43.941903Z","shell.execute_reply":"2025-08-01T07:42:46.551898Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- no clear drift between train and test data","metadata":{}},{"cell_type":"markdown","source":"## 4. Correlation check for train and test data","metadata":{}},{"cell_type":"markdown","source":" 0   id         250000 non-null  int64 \n 1   age        250000 non-null  int64 \n 2   job        250000 non-null  object\n 3   marital    250000 non-null  object\n 4   education  250000 non-null  object\n 5   default    250000 non-null  object\n 6   balance    250000 non-null  int64 \n 7   housing    250000 non-null  object\n 8   loan       250000 non-null  object\n 9   contact    250000 non-null  object\n 10  day        250000 non-null  int64 \n 11  month      250000 non-null  object\n 12  duration   250000 non-null  int64 \n 13  campaign   250000 non-null  int64 \n 14  pdays      250000 non-null  int64 \n 15  previous   250000 non-null  int64 \n 16  poutcome   250000 non-null  object","metadata":{}},{"cell_type":"code","source":"sns.heatmap(train_df[['age', 'balance','day', 'duration','campaign', 'pdays','previous']].corr(),\n            annot = True, cmap='coolwarm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:10:36.071416Z","iopub.execute_input":"2025-08-01T07:10:36.072126Z","iopub.status.idle":"2025-08-01T07:10:36.647210Z","shell.execute_reply.started":"2025-08-01T07:10:36.072098Z","shell.execute_reply":"2025-08-01T07:10:36.646216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.heatmap(test_df[['age', 'balance','day', 'duration','campaign', 'pdays','previous']].corr(), \n            annot = True, cmap='coolwarm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:11:24.655028Z","iopub.execute_input":"2025-08-01T07:11:24.655382Z","iopub.status.idle":"2025-08-01T07:11:25.068930Z","shell.execute_reply.started":"2025-08-01T07:11:24.655359Z","shell.execute_reply":"2025-08-01T07:11:25.068124Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- The Time_spend_alone column has a negative correlation with all the other columns\n- The remaining columns have also quite strong correlation with each other\n- The correlations for training and test data look very similar","metadata":{}},{"cell_type":"markdown","source":"## 5. Check of 'y' in each column for train data","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=train_df, x='y')\nround(train_df['y'].value_counts(normalize=True)*100,2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:11:45.732892Z","iopub.execute_input":"2025-08-01T07:11:45.733241Z","iopub.status.idle":"2025-08-01T07:11:45.924631Z","shell.execute_reply.started":"2025-08-01T07:11:45.733210Z","shell.execute_reply":"2025-08-01T07:11:45.923680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns = [ 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'day', 'month' , 'poutcome', 'age', 'campaign', 'previous']\nfor col in columns:\n    train_df.groupby([col,'y']).size().unstack().plot(kind='bar', stacked=True, title=col)\n    plt.show()\n    display((pd.crosstab(train_df[col], train_df[\"y\"], normalize='index') * 100).round(1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:58:27.003651Z","iopub.execute_input":"2025-08-01T08:58:27.004014Z","iopub.status.idle":"2025-08-01T08:58:32.701482Z","shell.execute_reply.started":"2025-08-01T08:58:27.003989Z","shell.execute_reply":"2025-08-01T08:58:32.700536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns = [ 'age', 'campaign', 'previous', 'pdays']\n\nfor feature in columns:\n    plt.figure(figsize=(8, 4))\n    sns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, label='Klasa 0', fill=True, alpha=0.4)\n    sns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, label='Klasa 1', fill=True, alpha=0.4)\n    plt.title(f'KDE dla {feature}')\n    #plt.xscale('log')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T09:44:13.674493Z","iopub.execute_input":"2025-08-01T09:44:13.675362Z","iopub.status.idle":"2025-08-01T09:44:27.853235Z","shell.execute_reply.started":"2025-08-01T09:44:13.675312Z","shell.execute_reply":"2025-08-01T09:44:27.852381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns = [ 'campaign', 'previous', 'pdays']\n\nfor feature in columns:\n\n    upper_limit = train_df[feature].quantile(0.9)  # lub np. 50, je≈õli chcesz rƒôcznie\n    plt.figure(figsize=(10, 5))\n    sns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, label='Klasa 0', fill=True, alpha=0.4)\n    sns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, label='Klasa 1', fill=True, alpha=0.4)\n    plt.xlim(-3, upper_limit)\n    plt.title(f'Przyciƒôty KDE dla {feature}')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T09:45:08.036377Z","iopub.execute_input":"2025-08-01T09:45:08.036695Z","iopub.status.idle":"2025-08-01T09:45:18.473895Z","shell.execute_reply.started":"2025-08-01T09:45:08.036675Z","shell.execute_reply":"2025-08-01T09:45:18.472939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature ='previous'\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\nupper_limit = train_df[feature].quantile(0.99)\n\n# Przyciƒôty\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[0], label='Klasa 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[0], label='Klasa 1', fill=True, alpha=0.4)\naxes[0].set_xlim(0, upper_limit)\naxes[0].set_title('Przyciƒôty zakres')\n\n# Pe≈Çen\nsns.kdeplot(data=train_df[train_df['y'] == 0], x=feature, ax=axes[1], label='Klasa 0', fill=True, alpha=0.4)\nsns.kdeplot(data=train_df[train_df['y'] == 1], x=feature, ax=axes[1], label='Klasa 1', fill=True, alpha=0.4)\naxes[1].set_title('Pe≈Çen zakres')\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:33:42.572705Z","iopub.execute_input":"2025-08-01T08:33:42.573038Z","iopub.status.idle":"2025-08-01T08:33:49.441204Z","shell.execute_reply.started":"2025-08-01T08:33:42.573016Z","shell.execute_reply":"2025-08-01T08:33:49.440255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns = ['campaign', 'previous']\n\ntrain_df[train_df['campaign']<10].groupby(['campaign','y']).size().unstack().plot(kind='bar', stacked=True, title=col)\nplt.show()\n\ntrain_df[train_df['previous']<16].groupby(['previous','y']).size().unstack().plot(kind='bar', stacked=True, title=col)\nplt.show()\n\n    #display((pd.crosstab(train_df[col], train_df[\"y\"], normalize='index') * 100).round(1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T09:41:52.475924Z","iopub.execute_input":"2025-08-01T09:41:52.476262Z","iopub.status.idle":"2025-08-01T09:41:53.143578Z","shell.execute_reply.started":"2025-08-01T09:41:52.476239Z","shell.execute_reply":"2025-08-01T09:41:53.142533Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- We have 2 gropus in label column with split 74% 26% - classes are not balanced\n- Data in numeric column are integer\n- Each column show integer values dominated by one group, transition integer values and values dominated by other group\n- Stage_fear and Drained_after_socializing columns show strong polarisation of data and similar character\n- There is no clear integer values column that is only introvert or extrovert","metadata":{}},{"cell_type":"markdown","source":"1. Czasowe i kampanijne zale≈ºno≈õci\n‚è±Ô∏è ‚ÄûD≈Çugo≈õƒá kontaktu‚Äù / ‚Äûliczba kontakt√≥w‚Äù\nkontakt_avg_time = duration / campaign ‚Äì ≈õredni czas kontaktu na jeden kontakt\n\nüìâ Trend kontakt√≥w\ndelta_contact = previous - campaign ‚Äì czy liczba kontakt√≥w wzros≈Ça czy spad≈Ça\n\nhas_previous_contact = (pdays != 999).astype(int) ‚Äì flaga, czy kontakt by≈Ç wcze≈õniej\n\nüìÖ Sezonowo≈õƒá\nZmienna month ‚Äì zakoduj jƒÖ jako int (np. Jan = 1) i dodaj zmiennƒÖ:\n\nis_q4_campaign = month.isin(['oct', 'nov', 'dec']) ‚Äì mo≈ºe zimƒÖ skuteczno≈õƒá spada?\n\nüßë‚Äçüíº 2. Zachowanie klienta i profil demograficzny\nüí≥ ZobowiƒÖzania finansowe\nloan_sum = (housing == 'yes') + (loan == 'yes') ‚Äì liczba aktywnych po≈ºyczek\n\nis_deep_debt = (balance < 0) & (loan_sum > 1) ‚Äì mocno zad≈Çu≈ºony\n\nüß† Poziom edukacji + zaw√≥d\nedu_job = education + \"_\" + job ‚Äì np. \"tertiary_admin\"\n\nMo≈ºna zakodowaƒá i u≈ºyƒá jako cechy (one-hot lub target encoding)\n\nüë´ Ma≈Ç≈ºe≈Ñstwo vs. wiek\nis_young_single = (age < 30) & (marital == 'single')\n\nis_old_married = (age > 60) & (marital == 'married')\n\nüìû 3. Komunikacja i kana≈Ç kontaktu\nüîî Efektywno≈õƒá kana≈Çu kontaktu\ncontact_success_rate = campaign / (duration + 1) ‚Äì ile kontakt√≥w na minutƒô\n\nüõ†Ô∏è Rodzaj komunikacji + sukces poprzedni\nchannel_prev_success = contact + \"_\" + poutcome\n\n\n\nüß™ Narzƒôdzia do wykrywania nieliniowych zale≈ºno≈õci:\npd.plotting.scatter_matrix() ‚Äì szybki rzut oka\n\nsns.pairplot() ‚Äì dla ma≈Çej liczby kolumn\n\nsklearn.feature_selection.mutual_info_classif(X, y) ‚Äì mierzy nieliniowƒÖ zale≈ºno≈õƒá","metadata":{}},{"cell_type":"markdown","source":"1. Numeryczne ‚Üî Numeryczne\nPairplot (sns.pairplot)\nKilka zmiennych naraz ‚Äì przeglƒÖd zale≈ºno≈õci i gƒôsto≈õci\nsns.pairplot(df, hue='label')  # opcjonalnie hue dla klasy binarnej\n\nScatterplot z hue / style / size\nSuper do odkrywania nieliniowych relacji\nsns.scatterplot(data=df, x='age', y='balance', hue='loan', style='marital')\n\nHeatmap korelacji (sns.heatmap)\nPokazuje mocne lub s≈Çabe powiƒÖzania liniowe\nsns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n\n2. Kategoryczne ‚Üî Numeryczne\nBoxplot (sns.boxplot)\nWidaƒá mediany, rozrzut i outliery\nsns.boxplot(data=df, x='education', y='balance')\n\nViolinplot (sns.violinplot)\nTo samo co boxplot, ale z KDE ‚Äì pokazuje lepiej gƒôsto≈õci\nsns.violinplot(data=df, x='job', y='age', hue='y', split=True)\n\nSwarmplot (sns.swarmplot)\nKa≈ºdy punkt osobno ‚Äì dobry na ma≈Çych zbiorach\nsns.swarmplot(data=df, x='marital', y='balance')\n\nBarplot (sns.barplot)\n≈örednia warto≈õƒá cechy numerycznej dla kategorii (np. ≈õredni balance dla job)\nsns.barplot(data=df, x='job', y='balance')\n\n 3. Kategoryczne ‚Üî Kategoryczne\nHeatmap cross-tab (pd.crosstab + sns.heatmap)\nIle wystƒÖpie≈Ñ danego po≈ÇƒÖczenia\nct = pd.crosstab(df['job'], df['marital'])\nsns.heatmap(ct, annot=True, fmt='d', cmap='Blues')\n\nCountplot (sns.countplot)\nLiczba obserwacji w ka≈ºdej kategorii + hue np. y\nsns.countplot(data=df, x='education', hue='y')\n\n4. Numeryczne ‚Üî Target binarny\nKDE Plot (sns.kdeplot)\nRozk≈Çad cechy w dw√≥ch klasach\nsns.kdeplot(data=df[df['y'] == 0], x='age', label='No Loan')\nsns.kdeplot(data=df[df['y'] == 1], x='age', label='Loan Taken')\n\nHistogram + hue\nsns.histplot(data=df, x='balance', hue='y', bins=30, kde=True, stat='density')\nüîπ 5. Dodatkowe / Interaktywne\n‚úÖ FacetGrid\nPodzielone wykresy np. wed≈Çug marital i education\ng = sns.FacetGrid(df, col=\"marital\", row=\"education\", hue=\"y\")\ng.map(sns.kdeplot, \"age\", fill=True)\n\njointplot (sns.jointplot)\nScatter + marginesowe rozk≈Çady\nsns.jointplot(data=df, x='balance', y='duration', hue='y', kind='kde')\n\n","metadata":{}},{"cell_type":"markdown","source":"## 6. Detailed check of categorical columns properties","metadata":{}},{"cell_type":"code","source":"sns.catplot(\n    data=train_df[train_df['Personality'].isin(['Introvert', 'Extrovert'])],  \n    x=\"Stage_fear\",\n    hue=\"Personality\",\n    col=\"Drained_after_socializing\",\n    kind=\"count\",\n    height=4,\n    aspect=1\n)\nplt.suptitle(\"Rozk≈Çad StageFear wg osobowo≈õci\", y=1.05)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:41.783486Z","iopub.execute_input":"2025-07-30T15:16:41.783782Z","iopub.status.idle":"2025-07-30T15:16:42.312738Z","shell.execute_reply.started":"2025-07-30T15:16:41.783764Z","shell.execute_reply":"2025-07-30T15:16:42.311764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.crosstab([train_df['Personality'],train_df[\"Stage_fear\"]],train_df[\"Drained_after_socializing\"]  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:42.313743Z","iopub.execute_input":"2025-07-30T15:16:42.314255Z","iopub.status.idle":"2025-07-30T15:16:42.336829Z","shell.execute_reply.started":"2025-07-30T15:16:42.314226Z","shell.execute_reply":"2025-07-30T15:16:42.335793Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- Stage_fear and Drained_after_socializing columns seems to be strong indicator of classification\n- In each column there is small representation of opposite group prefference (Extrovert preffers No & No, but there is small group of introverts with same prefferences)\n- It is very rare situation to have Yes - No and No - Yes answers. It is very specific minor group\n- It may be resonable to impute data Yes when other column is Yes and oposite for No, for such rare cases\n","metadata":{}},{"cell_type":"markdown","source":"####  Below we check what would be result of imputation Yes to Yes and No to No for both ways","metadata":{}},{"cell_type":"code","source":"cat_cols1 = ['Stage_fear','Drained_after_socializing']\nall_train_df=train_df[['Stage_fear','Drained_after_socializing','Personality']].copy()\nall_train_df[cat_cols1]=all_train_df[cat_cols1].fillna('Missing').astype(str)\ndisplay(pd.crosstab([all_train_df['Personality'],all_train_df[\"Stage_fear\"]],all_train_df[\"Drained_after_socializing\"]  ))\n\n\nhelp_train_df = train_df[['Stage_fear','Drained_after_socializing','Personality']].copy()\nhelp_train_df['Stage_fear'] = help_train_df['Stage_fear'].mask(help_train_df['Stage_fear'].isna() & help_train_df['Drained_after_socializing']\n                                            .notna(), help_train_df['Drained_after_socializing'])\nhelp_train_df['Drained_after_socializing'] = help_train_df['Drained_after_socializing'].mask(help_train_df['Drained_after_socializing']\n                                            .isna() & help_train_df['Stage_fear'].notna(), help_train_df['Stage_fear'])\nhelp_train_df[cat_cols1]=help_train_df[cat_cols1].fillna('Missing').astype(str)\n\ndisplay(pd.crosstab(help_train_df['Stage_fear'],help_train_df['Personality']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:42.337764Z","iopub.execute_input":"2025-07-30T15:16:42.338083Z","iopub.status.idle":"2025-07-30T15:16:42.391355Z","shell.execute_reply.started":"2025-07-30T15:16:42.338055Z","shell.execute_reply":"2025-07-30T15:16:42.390427Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- There is only 39 missing values for both categorical columns and for total 18524 rows it seems to be a good imputation stratego - to be tested","metadata":{}},{"cell_type":"markdown","source":"## 7. Detailed check of No-No / Yes-Yes data regarding Introverts & Extroverts groups","metadata":{}},{"cell_type":"code","source":"train_introvert_df = train_df[train_df['Personality']=='Introvert']\ntrain_extrovert_df = train_df[train_df['Personality']=='Extrovert']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:42.392153Z","iopub.execute_input":"2025-07-30T15:16:42.392448Z","iopub.status.idle":"2025-07-30T15:16:42.403552Z","shell.execute_reply.started":"2025-07-30T15:16:42.392428Z","shell.execute_reply":"2025-07-30T15:16:42.402587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"introvert_no_no_df = train_df[(train_df[\"Stage_fear\"]=='No') & (train_df[\"Drained_after_socializing\"]=='No') & (train_df['Personality']=='Introvert')]\nextrovert_yes_yes_df = train_df[(train_df[\"Stage_fear\"]=='Yes') & (train_df[\"Drained_after_socializing\"]=='Yes') & (train_df['Personality']=='Extrovert')]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:42.404168Z","iopub.execute_input":"2025-07-30T15:16:42.404757Z","iopub.status.idle":"2025-07-30T15:16:42.431171Z","shell.execute_reply.started":"2025-07-30T15:16:42.404725Z","shell.execute_reply":"2025-07-30T15:16:42.430444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in columns:\n    if train_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(introvert_no_no_df[col], label='introvert with no-no', fill=True)\n        sns.kdeplot(train_introvert_df[col], label='train_df introvert', fill=True)\n        sns.kdeplot(train_extrovert_df[col], label='train_df extrovert', fill=True)\n        plt.legend()\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:42.432078Z","iopub.execute_input":"2025-07-30T15:16:42.432382Z","iopub.status.idle":"2025-07-30T15:16:44.502861Z","shell.execute_reply.started":"2025-07-30T15:16:42.432351Z","shell.execute_reply":"2025-07-30T15:16:44.501941Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in columns:\n    if train_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(extrovert_yes_yes_df[col], label='extrovert with yes-yes', fill=True)\n        sns.kdeplot(train_introvert_df[col], label='train_df introvert', fill=True)\n        sns.kdeplot(train_extrovert_df[col], label='train_df extrovert', fill=True)\n        plt.legend()\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:44.503790Z","iopub.execute_input":"2025-07-30T15:16:44.504434Z","iopub.status.idle":"2025-07-30T15:16:46.314830Z","shell.execute_reply.started":"2025-07-30T15:16:44.504411Z","shell.execute_reply":"2025-07-30T15:16:46.313783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in columns:\n    if train_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(extrovert_yes_yes_df[col], label='extrovert with yes-yes', fill=True)\n        sns.kdeplot(train_introvert_df[col], label='train_df introvert', fill=True)\n        sns.kdeplot(train_extrovert_df[col], label='train_df extrovert', fill=True)\n        sns.kdeplot(introvert_no_no_df[col], label='introvert with no-no', fill=True)\n        plt.legend()\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:46.315862Z","iopub.execute_input":"2025-07-30T15:16:46.316160Z","iopub.status.idle":"2025-07-30T15:16:48.283527Z","shell.execute_reply.started":"2025-07-30T15:16:46.316132Z","shell.execute_reply":"2025-07-30T15:16:48.282623Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- It seems like main problem of this classification. No-No answer is typical for Extroverts but some Introverts have same prefferences like No-No and has similar values for other colums (Post_frequency, Going_outsice...) like Extroverts\n- It will be extremly hard for classifiers to deal with such situation. There is some space in overlaping area between yes-yes and no-no groups and it can be marked with 0 and 1 giving clear information to model that is border condition. - Can be tested ","metadata":{}},{"cell_type":"code","source":"for col in test_df.columns:\n    if col != 'id' and test_df[col].dtype in[np.int64,np.float64]:\n        sns.kdeplot(introvert_no_no_df[col], label='introvert with no-no', fill=True)\n        sns.kdeplot(extrovert_yes_yes_df[col], label='extrovert with yes-yes', fill=True)\n\n        plt.legend()\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:48.284661Z","iopub.execute_input":"2025-07-30T15:16:48.285005Z","iopub.status.idle":"2025-07-30T15:16:49.452396Z","shell.execute_reply.started":"2025-07-30T15:16:48.284978Z","shell.execute_reply":"2025-07-30T15:16:49.451600Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Markers to be tested:\n- 'Time_spent_Alone' == 4\n- 'Social_event_attendance' == 3\n- 'Going_outside' ==3\n- 'Friends_circle_size' == 5\n- 'Post_frequency' == 3","metadata":{"execution":{"iopub.status.busy":"2025-07-30T07:33:32.890719Z","iopub.execute_input":"2025-07-30T07:33:32.891163Z","iopub.status.idle":"2025-07-30T07:33:32.897390Z","shell.execute_reply.started":"2025-07-30T07:33:32.891135Z","shell.execute_reply":"2025-07-30T07:33:32.895495Z"}}},{"cell_type":"markdown","source":"## 8. Missing values - looking for signals","metadata":{}},{"cell_type":"code","source":"excluded_cols = ['id', 'Personality']\nall_columns = train_df.columns\nfor col in all_columns:\n    if col not in excluded_cols:\n        train_df[col + '_MISS'] = train_df[col].notna().astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:49.453256Z","iopub.execute_input":"2025-07-30T15:16:49.453481Z","iopub.status.idle":"2025-07-30T15:16:49.465341Z","shell.execute_reply.started":"2025-07-30T15:16:49.453464Z","shell.execute_reply":"2025-07-30T15:16:49.464654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns = ['Time_spent_Alone_MISS','Stage_fear_MISS', 'Social_event_attendance_MISS', 'Going_outside_MISS','Drained_after_socializing_MISS', \n           'Friends_circle_size_MISS','Post_frequency_MISS']\nfor col in columns:\n    train_df.groupby([col,'Personality']).size().unstack().plot(kind='bar', stacked=True, title=col)\n    result = pd.crosstab(train_df[col],train_df['Personality'], normalize='index')*100\n    chi2, p, _, _ = chi2_contingency(result)\n    print(f\"Chi2 = {chi2:.3f}, p-value = {p:.4f} Column: {col} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:49.466159Z","iopub.execute_input":"2025-07-30T15:16:49.466444Z","iopub.status.idle":"2025-07-30T15:16:51.204088Z","shell.execute_reply.started":"2025-07-30T15:16:49.466424Z","shell.execute_reply":"2025-07-30T15:16:51.203182Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- Columns Stage_fear_MISS and Drained_after_socializing_MISS have p-value lower then 0.05 so they can be considered as potential signal for different distribution of Introverts/Extroverts","metadata":{}},{"cell_type":"markdown","source":"## 9. Missing values - total number of non-missing data","metadata":{}},{"cell_type":"code","source":"train_df['not_MISS_total'] = train_df[columns].sum(axis=1)\ntrain_df.groupby(['not_MISS_total','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Data without NaN values')\npd.crosstab(train_df['not_MISS_total'],train_df['Personality'], normalize='index')*100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:51.204993Z","iopub.execute_input":"2025-07-30T15:16:51.205330Z","iopub.status.idle":"2025-07-30T15:16:51.434952Z","shell.execute_reply.started":"2025-07-30T15:16:51.205310Z","shell.execute_reply":"2025-07-30T15:16:51.434030Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- When number of missing values for one person increase it is observed that percentage of introverts in such grup increases too. ","metadata":{}},{"cell_type":"markdown","source":"## 10. Advanced Data Imputation ","metadata":{}},{"cell_type":"code","source":"num_cols = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size','Post_frequency']    \ncat_cols = ['Stage_fear', 'Drained_after_socializing']     \n\ncat_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n\ntrain_df[cat_cols] = cat_encoder.fit_transform(train_df[cat_cols])\nnum_imputer = IterativeImputer(estimator=LGBMRegressor(n_estimators=500, learning_rate=0.03, max_depth=6, subsample=0.8, colsample_bytree=0.8, verbosity=-1),\n                               max_iter=10, random_state=42)\n\ntrain_df[num_cols] = num_imputer.fit_transform(train_df[num_cols])\ncat_imputer = IterativeImputer(estimator=LGBMClassifier(n_estimators=500, learning_rate=0.03, max_depth=6, subsample=0.8, colsample_bytree=0.8, class_weght='balanced', verbosity=-1),\n                               max_iter=10, random_state=42)\n\ntrain_df[cat_cols] = cat_imputer.fit_transform(train_df[cat_cols])\n\ncolumns = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size','Post_frequency']\ntrain_df[columns]=train_df[columns].round().astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:16:51.435978Z","iopub.execute_input":"2025-07-30T15:16:51.436311Z","iopub.status.idle":"2025-07-30T15:17:17.544116Z","shell.execute_reply.started":"2025-07-30T15:16:51.436285Z","shell.execute_reply":"2025-07-30T15:17:17.543127Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11. Realations check between columns","metadata":{"execution":{"iopub.status.busy":"2025-07-26T14:48:08.993241Z","iopub.execute_input":"2025-07-26T14:48:08.993576Z","iopub.status.idle":"2025-07-26T14:48:08.997773Z","shell.execute_reply.started":"2025-07-26T14:48:08.993554Z","shell.execute_reply":"2025-07-26T14:48:08.996803Z"}}},{"cell_type":"markdown","source":"### Time_spent_Alone / Going_outside","metadata":{"execution":{"iopub.status.busy":"2025-07-26T16:07:28.446182Z","iopub.execute_input":"2025-07-26T16:07:28.446498Z","iopub.status.idle":"2025-07-26T16:07:28.451114Z","shell.execute_reply.started":"2025-07-26T16:07:28.446474Z","shell.execute_reply":"2025-07-26T16:07:28.449714Z"}}},{"cell_type":"code","source":"train_df['Time_Alone_dev_Outside'] = train_df['Time_spent_Alone'] / train_df['Going_outside']\ntrain_df['Time_Alone_dev_Outside']=train_df['Time_Alone_dev_Outside'].round(2).astype(float)\ntrain_df.groupby(['Time_Alone_dev_Outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:17.851341Z","iopub.execute_input":"2025-07-30T15:18:17.852377Z","iopub.status.idle":"2025-07-30T15:18:18.477157Z","shell.execute_reply.started":"2025-07-30T15:18:17.852350Z","shell.execute_reply":"2025-07-30T15:18:18.476030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Time_Alone_dev_Outside (x):\n    try:\n        x=float(x)\n        if x <= 1:\n            return 0\n        elif x > 1 and x < 2:\n            return 1\n        elif x >= 2 and x < 100:\n            return 2\n        else:\n            return 3\n    except ValueError:\n        return 3\n\ntrain_df['Time_Alone_dev_Outside']=train_df['Time_Alone_dev_Outside'].apply(Time_Alone_dev_Outside).astype('Int64')\ntrain_df.groupby(['Time_Alone_dev_Outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\npd.crosstab(train_df[\"Time_Alone_dev_Outside\"],train_df['Personality'],normalize='index')*100 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:18.478666Z","iopub.execute_input":"2025-07-30T15:18:18.478950Z","iopub.status.idle":"2025-07-30T15:18:18.735834Z","shell.execute_reply.started":"2025-07-30T15:18:18.478929Z","shell.execute_reply":"2025-07-30T15:18:18.735064Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- If columns Time_spent_Alone / Going_outside are devided we can observed quite good separation of data\n- To reduce number of features we can use clustering or write simple function, each group have different ratio\n- Can be check as additional feature to recognise groups","metadata":{"execution":{"iopub.status.busy":"2025-07-30T13:50:14.224526Z","iopub.execute_input":"2025-07-30T13:50:14.224816Z","iopub.status.idle":"2025-07-30T13:50:14.230744Z","shell.execute_reply.started":"2025-07-30T13:50:14.224796Z","shell.execute_reply":"2025-07-30T13:50:14.229624Z"}}},{"cell_type":"markdown","source":"## Social_event_attendance / Post_frequency","metadata":{}},{"cell_type":"code","source":"train_df['Social_dev_Post'] = train_df['Social_event_attendance'] / train_df['Post_frequency']\ntrain_df['Social_dev_Post']=train_df['Social_dev_Post'].round(2).astype(float)\ntrain_df.groupby(['Social_dev_Post','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:18.736644Z","iopub.execute_input":"2025-07-30T15:18:18.736882Z","iopub.status.idle":"2025-07-30T15:18:19.397347Z","shell.execute_reply.started":"2025-07-30T15:18:18.736865Z","shell.execute_reply":"2025-07-30T15:18:19.396494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Alternatywne grupowanie\ntrain_df['Social_dev_Post'] = train_df['Social_event_attendance'] / train_df['Post_frequency']\ntrain_df['Social_dev_Post']=train_df['Social_dev_Post'].round(2).astype(float)\n\ndef Social_dev_Post (x):\n    try:\n        x=float(x)\n        if x == 0:\n            return 0\n        elif x > 0 and x < 0.33:\n            return 1\n        elif x == 0.33:\n            return 2\n        elif x > 0.33 and x < 0.5:\n            return 1\n        elif x == 0.5:\n            return 4\n        elif x > 0.5 and x < 0.67:\n            return 1\n        elif x == 0.67:\n            return 4\n        elif x > 0.67 and x < 1:\n            return 1\n        elif x == 1:\n            return 4\n        elif x > 1 and x < 1.5:\n            return 1\n        elif x == 1.5:\n            return 4\n        elif x > 1.5 and x < 2:\n            return 1\n        elif x == 2:\n            return 4\n        elif x > 2 and x < 3:\n            return 1\n        elif x == 3:\n            return 2\n        elif x > 3 and x < 100:\n            return 1\n        else:\n            return 0\n    except ValueError:\n        return 0\n\ntrain_df['Social_dev_Post']=train_df['Social_dev_Post'].apply(Social_dev_Post).astype('Int64')\ntrain_df.groupby(['Social_dev_Post','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\npd.crosstab(train_df[\"Social_dev_Post\"],train_df['Personality'], normalize='index')*100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:19.399292Z","iopub.execute_input":"2025-07-30T15:18:19.399573Z","iopub.status.idle":"2025-07-30T15:18:19.622732Z","shell.execute_reply.started":"2025-07-30T15:18:19.399554Z","shell.execute_reply":"2025-07-30T15:18:19.621956Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- If columns Social_event_attendance / Post_frequency are devided we can observed quite good separation of data in fixed points\n- To reduce number of features we can use clustering or write simple function, each group have different ratio\n- Can be check as additional feature to recognise groups","metadata":{}},{"cell_type":"markdown","source":"## Going_outside * Friends_circle_size","metadata":{}},{"cell_type":"code","source":"train_df['Outside_mult_Friends'] = train_df['Going_outside'] * train_df['Friends_circle_size']\ntrain_df.groupby(['Outside_mult_Friends','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:19.623572Z","iopub.execute_input":"2025-07-30T15:18:19.623836Z","iopub.status.idle":"2025-07-30T15:18:20.238677Z","shell.execute_reply.started":"2025-07-30T15:18:19.623807Z","shell.execute_reply":"2025-07-30T15:18:20.237791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Outside_mult_Friends (x):\n    try:\n        x=float(x)\n        if x <= 11:\n            return 0\n        elif x > 11 and x <= 15:\n            return 1\n        elif x > 15 and x < 400:\n            return 2\n        else:\n            return 2\n    except ValueError:\n        return 2\n\ntrain_df['Outside_mult_Friends']=train_df['Outside_mult_Friends'].apply(Outside_mult_Friends).astype('Int64')\ntrain_df.groupby(['Outside_mult_Friends','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\npd.crosstab(train_df[\"Outside_mult_Friends\"],train_df['Personality'], normalize='index')*100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:20.239528Z","iopub.execute_input":"2025-07-30T15:18:20.239794Z","iopub.status.idle":"2025-07-30T15:18:20.494894Z","shell.execute_reply.started":"2025-07-30T15:18:20.239767Z","shell.execute_reply":"2025-07-30T15:18:20.493562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- If columns Going_outside * Friends_circle_size are multiplied we can observed quite good separation of data \n- To reduce number of features we can use clustering or write simple function, each group have different ratio\n- Can be check as additional feature to recognise groups","metadata":{}},{"cell_type":"markdown","source":"## Going_outside - Post_frequency","metadata":{}},{"cell_type":"code","source":"train_df['Going_sub_Post']=train_df['Going_outside'] - train_df['Post_frequency']\ntrain_df.groupby(['Going_sub_Post','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:20.495978Z","iopub.execute_input":"2025-07-30T15:18:20.497006Z","iopub.status.idle":"2025-07-30T15:18:20.818052Z","shell.execute_reply.started":"2025-07-30T15:18:20.496972Z","shell.execute_reply":"2025-07-30T15:18:20.817255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Outside_mult_Friends (x):\n    try:\n        x=float(x)\n        if x <= -6:\n            return 0\n        elif x == -5 or x== -4 or x==4:\n            return 1\n        elif x == -3 or x== 3:\n            return 2\n        elif x == -2 or x== 2:\n            return 3\n        elif x == -1 or x== 0 or x==1:\n            return 4\n        elif x >= 5:\n            return 5\n        else:\n            return 6\n    except ValueError:\n        return 6\n\ntrain_df['Going_sub_Post']=train_df['Going_sub_Post'].apply(Outside_mult_Friends).astype('Int64')\ntrain_df.groupby(['Going_sub_Post','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\npd.crosstab(train_df[\"Going_sub_Post\"],train_df['Personality'], normalize='index')*100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:20.819029Z","iopub.execute_input":"2025-07-30T15:18:20.819358Z","iopub.status.idle":"2025-07-30T15:18:21.054202Z","shell.execute_reply.started":"2025-07-30T15:18:20.819333Z","shell.execute_reply":"2025-07-30T15:18:21.053369Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- If columns Going_outside - Post_frequency are subtracted from each other we can observed quite good separation of data \n- To reduce number of features we can use clustering or write simple function, each group have different ratio\n- Can be check as additional feature to recognise groups\n- group 0 is still not pure group","metadata":{}},{"cell_type":"markdown","source":"## 12. Realations check between columns - Other ","metadata":{}},{"cell_type":"markdown","source":"## Columns subtraction","metadata":{}},{"cell_type":"code","source":"train_df['subtraction']=train_df['Friends_circle_size'] - train_df['Post_frequency']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:21.054958Z","iopub.execute_input":"2025-07-30T15:18:21.055203Z","iopub.status.idle":"2025-07-30T15:18:21.629306Z","shell.execute_reply.started":"2025-07-30T15:18:21.055169Z","shell.execute_reply":"2025-07-30T15:18:21.628519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Going_outside'] - train_df['Post_frequency']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:21.632242Z","iopub.execute_input":"2025-07-30T15:18:21.632485Z","iopub.status.idle":"2025-07-30T15:18:21.924539Z","shell.execute_reply.started":"2025-07-30T15:18:21.632467Z","shell.execute_reply":"2025-07-30T15:18:21.923711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Going_outside'] - train_df['Friends_circle_size']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:21.925389Z","iopub.execute_input":"2025-07-30T15:18:21.925665Z","iopub.status.idle":"2025-07-30T15:18:22.287676Z","shell.execute_reply.started":"2025-07-30T15:18:21.925647Z","shell.execute_reply":"2025-07-30T15:18:22.286730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Social_event_attendance'] - train_df['Post_frequency']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:22.288505Z","iopub.execute_input":"2025-07-30T15:18:22.288738Z","iopub.status.idle":"2025-07-30T15:18:22.608100Z","shell.execute_reply.started":"2025-07-30T15:18:22.288719Z","shell.execute_reply":"2025-07-30T15:18:22.607237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Social_event_attendance'] - train_df['Friends_circle_size']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:22.609039Z","iopub.execute_input":"2025-07-30T15:18:22.609369Z","iopub.status.idle":"2025-07-30T15:18:22.948848Z","shell.execute_reply.started":"2025-07-30T15:18:22.609342Z","shell.execute_reply":"2025-07-30T15:18:22.948005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Social_event_attendance'] - train_df['Going_outside']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:22.949773Z","iopub.execute_input":"2025-07-30T15:18:22.950018Z","iopub.status.idle":"2025-07-30T15:18:23.270327Z","shell.execute_reply.started":"2025-07-30T15:18:22.950001Z","shell.execute_reply":"2025-07-30T15:18:23.269560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Time_spent_Alone'] - train_df['Post_frequency']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:23.271119Z","iopub.execute_input":"2025-07-30T15:18:23.271452Z","iopub.status.idle":"2025-07-30T15:18:23.639949Z","shell.execute_reply.started":"2025-07-30T15:18:23.271418Z","shell.execute_reply":"2025-07-30T15:18:23.639131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Time_spent_Alone'] - train_df['Friends_circle_size']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:23.640823Z","iopub.execute_input":"2025-07-30T15:18:23.641046Z","iopub.status.idle":"2025-07-30T15:18:24.028235Z","shell.execute_reply.started":"2025-07-30T15:18:23.641028Z","shell.execute_reply":"2025-07-30T15:18:24.027377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Time_spent_Alone'] - train_df['Going_outside']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:24.029281Z","iopub.execute_input":"2025-07-30T15:18:24.029677Z","iopub.status.idle":"2025-07-30T15:18:24.363166Z","shell.execute_reply.started":"2025-07-30T15:18:24.029645Z","shell.execute_reply":"2025-07-30T15:18:24.362394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['subtraction']=train_df['Time_spent_Alone'] - train_df['Social_event_attendance']\ntrain_df.groupby(['subtraction','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:24.363841Z","iopub.execute_input":"2025-07-30T15:18:24.364035Z","iopub.status.idle":"2025-07-30T15:18:24.696758Z","shell.execute_reply.started":"2025-07-30T15:18:24.364020Z","shell.execute_reply":"2025-07-30T15:18:24.695920Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Column summing","metadata":{}},{"cell_type":"code","source":"train_df['Summary']=train_df['Friends_circle_size'] + train_df['Post_frequency']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:24.697761Z","iopub.execute_input":"2025-07-30T15:18:24.698027Z","iopub.status.idle":"2025-07-30T15:18:25.073437Z","shell.execute_reply.started":"2025-07-30T15:18:24.697998Z","shell.execute_reply":"2025-07-30T15:18:25.072411Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Summary']=train_df['Going_outside'] + train_df['Friends_circle_size']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:25.074441Z","iopub.execute_input":"2025-07-30T15:18:25.074776Z","iopub.status.idle":"2025-07-30T15:18:25.432081Z","shell.execute_reply.started":"2025-07-30T15:18:25.074755Z","shell.execute_reply":"2025-07-30T15:18:25.431278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Summary']=train_df['Going_outside'] + train_df['Post_frequency']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:25.433311Z","iopub.execute_input":"2025-07-30T15:18:25.433668Z","iopub.status.idle":"2025-07-30T15:18:25.760430Z","shell.execute_reply.started":"2025-07-30T15:18:25.433637Z","shell.execute_reply":"2025-07-30T15:18:25.759543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Summary']=train_df['Social_event_attendance'] + train_df['Post_frequency']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:25.761456Z","iopub.execute_input":"2025-07-30T15:18:25.761711Z","iopub.status.idle":"2025-07-30T15:18:26.097687Z","shell.execute_reply.started":"2025-07-30T15:18:25.761681Z","shell.execute_reply":"2025-07-30T15:18:26.096884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Summary']=train_df['Social_event_attendance'] + train_df['Going_outside']\ntrain_df.groupby(['Summary','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:26.098949Z","iopub.execute_input":"2025-07-30T15:18:26.099293Z","iopub.status.idle":"2025-07-30T15:18:26.614242Z","shell.execute_reply.started":"2025-07-30T15:18:26.099267Z","shell.execute_reply":"2025-07-30T15:18:26.613396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Other column multiplications and divisions","metadata":{}},{"cell_type":"code","source":"train_df['Time_alona_outside'] = train_df['Going_outside'] / train_df['Post_frequency']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Social_event_attendance'] / train_df['Post_frequency']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Time_spent_Alone'] / train_df['Post_frequency']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Time_spent_Alone'] / train_df['Friends_circle_size']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Time_spent_Alone'] / train_df['Social_event_attendance']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alona_outside'] = train_df['Time_spent_Alone'] / train_df['Going_outside']\ntrain_df.groupby(['Time_alona_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Time_alone_friends_circle'] = train_df['Time_spent_Alone'] / train_df['Friends_circle_size']\ntrain_df.groupby(['Time_alone_friends_circle','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\n\ntrain_df['Social_event_outside'] = train_df['Going_outside'] * train_df['Social_event_attendance']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Social_event_outside'] = train_df['Social_event_attendance'] * train_df['Friends_circle_size']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Social_event_outside'] = train_df['Social_event_attendance'] * train_df['Post_frequency']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Social_event_outside'] = train_df['Going_outside'] * train_df['Friends_circle_size']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\n\ntrain_df['Social_event_outside'] = train_df['Going_outside'] * train_df['Post_frequency']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n\ntrain_df['Social_event_outside'] = train_df['Friends_circle_size'] * train_df['Post_frequency']\ntrain_df.groupby(['Social_event_outside','Personality']).size().unstack().plot(kind='bar', stacked=True, title='Summary')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:18:26.615343Z","iopub.execute_input":"2025-07-30T15:18:26.615649Z","iopub.status.idle":"2025-07-30T15:18:36.051383Z","shell.execute_reply.started":"2025-07-30T15:18:26.615623Z","shell.execute_reply":"2025-07-30T15:18:36.050424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n- For checked interactions there is no pure separation between Extroverts and Introverts\n- Some additional features can be created to be tested, if there is improvement in classification\n","metadata":{}}]}